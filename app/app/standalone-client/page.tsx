"use client";

import React, { useState, useCallback, useEffect, useRef } from 'react';
import Visualizer from '../../components/visualizer';
import Meyda from 'meyda'; // Import Meyda for real audio feature extraction
// åŠ¨æ€æŒ‰éœ€åŠ è½½ TFJSï¼Œé¿å…è¿›å…¥é¦–åŒ…
let tfNs: any = null;
import { DanmuEngine } from '../../lib/danmu-engine'; // Import DanmuEngine
import { useDanmuPipeline } from '../../hooks/useDanmuPipeline'; // Import LLM Danmu Pipeline

// æ´¾ç”Ÿç‰¹å¾è®¡ç®—å‡½æ•°
function calculateVoiceProbability(f: any): number {
  const flat = typeof f?.spectralFlatness === 'number' ? f.spectralFlatness : 0;
  const centroid = typeof f?.spectralCentroid === 'number' ? f.spectralCentroid : 0;
  
  const flatFactor = Math.max(0, Math.min(1, 1 - flat));
  const centroidNorm = Math.max(0, Math.min(1, (centroid - 1500) / 2500));
  
  return Math.max(0, Math.min(1, 0.35 + 0.4 * flatFactor + 0.25 * centroidNorm));
}

  function calculatePercussiveRatio(f: any): number {
    const flat = typeof f?.spectralFlatness === 'number' ? f.spectralFlatness : 0;
    const flux = 0; // spectralFlux å·²ç§»é™¤ï¼Œä½¿ç”¨é»˜è®¤å€¼
  
  const fluxNorm = Math.max(0, Math.min(1, flux * 1.4));
  const flatNorm = Math.max(0, Math.min(1, flat));
  
  return Math.max(0, Math.min(1, 0.45 * fluxNorm + 0.4 * flatNorm));
}

function calculateHarmonicRatio(f: any): number {
  const percussiveRatio = calculatePercussiveRatio(f);
  const voiceProb = calculateVoiceProbability(f);
  
  const base = 1 - percussiveRatio * 0.7;
  const voiceBoost = 0.2 * voiceProb;
  
  return Math.max(0, Math.min(1, base + voiceBoost));
}

// YAMNet ç›¸å…³å‡½æ•°
async function loadYAMNetModel(): Promise<any | null> {
  const TIMEOUT_MS = 2500;
  const withTimeout = <T,>(p: Promise<T>): Promise<T> => new Promise((resolve, reject) => {
    const t = setTimeout(() => reject(new Error('åŠ è½½è¶…æ—¶')), TIMEOUT_MS);
    p.then(v => { clearTimeout(t); resolve(v); }).catch(e => { clearTimeout(t); reject(e); });
  });

  // åŠ¨æ€åŠ è½½ TFJS æ ¸å¿ƒï¼ˆTFLite/GraphModel éƒ½éœ€è¦ï¼‰
  try {
    if (!tfNs && typeof window !== 'undefined') {
      tfNs = await withTimeout(import('@tensorflow/tfjs'));
      if (tfNs?.ready) { await tfNs.ready(); }
      console.log('TFJS å·²æŒ‰éœ€åŠ è½½');
    }
  } catch (e) {
    console.warn('TFJS åŠ è½½å¤±è´¥ï¼ˆå°†ä¾èµ–å¯å‘å¼/è·³è¿‡åˆ†ç±»ï¼‰:', e);
  }

  // 1) ä¼˜å…ˆå°è¯• TFLiteï¼ˆç§»åŠ¨ç«¯æ›´ç¨³ï¼‰
  try {
    console.log('å°è¯•åŠ è½½ YAMNet (TFLite)...');
    const tfliteNs = await withTimeout(import('@tensorflow/tfjs-tflite'));
    // å…³é”®ï¼šä¸º tfjs-tflite æŒ‡å®š wasm èµ„æºç›®å½•ï¼Œé¿å… 404/_malloc æŠ¥é”™
    try {
      const setWasmPaths = (tfliteNs as any)?.setWasmPaths;
      const CDN = 'https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-tflite/dist/';
      if (typeof setWasmPaths === 'function') {
        setWasmPaths(CDN);
        console.log('tfjs-tflite wasm è·¯å¾„å·²è®¾ç½®ä¸º CDN (module)');
      } else if ((globalThis as any)?.tfjsTflite?.setWasmPaths) {
        (globalThis as any).tfjsTflite.setWasmPaths(CDN);
        console.log('tfjs-tflite wasm è·¯å¾„å·²è®¾ç½®ä¸º CDN (global)');
      } else {
        console.warn('tfjs-tflite æœªæš´éœ² setWasmPathsï¼Œå°†å›é€€åˆ°æœ¬åœ° /tflite/');
        (tfliteNs as any)?.setWasmPaths?.('/tflite/');
      }
    } catch (e) {
      console.warn('è®¾ç½® tfjs-tflite wasm è·¯å¾„å¤±è´¥ï¼ˆå¯å¿½ç•¥ï¼‰:', e);
    }
    const tfliteModel = await withTimeout((tfliteNs as any).loadTFLiteModel('/model/yamnet_tflite/yamnet.tflite'));
    console.log('YAMNet (TFLite) åŠ è½½æˆåŠŸ');
    return tfliteModel; // ä½œä¸º any è¿”å›ï¼Œåç»­ä»¥ predict è°ƒç”¨
  } catch (e) {
    console.warn('YAMNet (TFLite) åŠ è½½å¤±è´¥ï¼Œå°†å°è¯• TFJS:', e);
  }

  // 2) å›é€€å°è¯• TFJS GraphModelï¼ˆè‹¥åç»­æˆ‘ä»¬æä¾›äº† /model/yamnet/model.jsonï¼‰
  try {
    console.log('å°è¯•åŠ è½½ YAMNet (TFJS GraphModel)...');
    if (!tfNs?.loadGraphModel) throw new Error('TFJS æœªå°±ç»ª');
    const graph = await withTimeout(tfNs.loadGraphModel('/model/yamnet/model.json'));
    console.log('YAMNet (GraphModel) åŠ è½½æˆåŠŸ');
    return graph;
  } catch (e) {
    console.warn('YAMNet (GraphModel) åŠ è½½å¤±è´¥:', e);
  }

  // 3) æœ€åå…¼å®¹æ—§é”™è¯¯è·¯å¾„ï¼ˆå¤§æ¦‚ç‡å¤±è´¥ï¼‰
  try {
    console.log('å°è¯•åŠ è½½ æ—§è·¯å¾„ï¼ˆä¸æ¨èï¼‰/model/yamnet.task');
    if (!tfNs?.loadLayersModel) throw new Error('TFJS æœªå°±ç»ª');
    const legacy = await withTimeout(tfNs.loadLayersModel('/model/yamnet.task'));
    console.log('YAMNet æ—§è·¯å¾„åŠ è½½æˆåŠŸï¼ˆä¸æ¨èï¼‰');
    return legacy;
  } catch (e) {
    console.warn('æ—§è·¯å¾„åŠ è½½å¤±è´¥ï¼ˆé¢„æœŸï¼‰:', e);
  }

  console.warn('YAMNet ä¸å¯ç”¨ï¼Œç»§ç»­ä½¿ç”¨å¯å‘å¼ç‰¹å¾ï¼ˆåŠŸèƒ½ä¸é˜»å¡ï¼‰ã€‚');
  return null;
}

function classifyWithYAMNet(model: any, audioBuffer: Float32Array): any {
  try {
    // YAMNet éœ€è¦ 16kHz é‡‡æ ·ç‡ï¼Œ0.975 ç§’çš„éŸ³é¢‘ (15600 æ ·æœ¬)
    const targetLength = 15600;
    const resampledBuffer = new Float32Array(targetLength);
    
    // ç®€å•çš„çº¿æ€§æ’å€¼é‡é‡‡æ ·
    const ratio = audioBuffer.length / targetLength;
    for (let i = 0; i < targetLength; i++) {
      const srcIndex = i * ratio;
      const index = Math.floor(srcIndex);
      const fraction = srcIndex - index;
      
      if (index + 1 < audioBuffer.length) {
        resampledBuffer[i] = audioBuffer[index] * (1 - fraction) + audioBuffer[index + 1] * fraction;
      } else {
        resampledBuffer[i] = audioBuffer[index] || 0;
      }
    }
    
    // åˆ›å»ºè¾“å…¥å¼ é‡ [1, 15600]
    if (!tfNs?.tensor2d) throw new Error('TFJS å¼ é‡ API ä¸å¯ç”¨');
    const input = tfNs.tensor2d([Array.from(resampledBuffer)], [1, targetLength]);
    
    // è¿è¡Œæ¨ç†
    const predictions = model.predict(input);
    const results = predictions.dataSync ? predictions.dataSync() : [];
    
    // æ¸…ç†å¼ é‡
    try { input.dispose?.(); } catch(_) {}
    try { predictions.dispose?.(); } catch(_) {}
    
    // æå–å‰5ä¸ªæœ€å¯èƒ½çš„ç±»åˆ«
    const topClasses = [] as Array<{ index: number; confidence: number; label: string }>;
    const resultsArray: number[] = Array.from(results as number[]);
    for (let i = 0; i < Math.min(5, resultsArray.length); i++) {
      const maxIndex = resultsArray.indexOf(Math.max(...resultsArray));
      topClasses.push({
        index: maxIndex,
        confidence: resultsArray[maxIndex],
        label: getYAMNetLabel(maxIndex)
      });
      resultsArray[maxIndex] = -1; // æ ‡è®°ä¸ºå·²å¤„ç†
    }
    
    return {
      topClasses,
      instruments: extractInstruments(topClasses),
      events: extractEvents(topClasses)
    };
  } catch (error) {
    console.error('YAMNet åˆ†ç±»å¤±è´¥:', error);
    return null;
  }
}

function getYAMNetLabel(index: number): string {
  // ç®€åŒ–çš„ YAMNet æ ‡ç­¾æ˜ å°„ï¼ˆå®é™…åº”è¯¥æœ‰å®Œæ•´çš„ 521 ä¸ªæ ‡ç­¾ï¼‰
  const labels: { [key: number]: string } = {
    0: 'Speech',
    1: 'Child speech, kid speaking',
    2: 'Conversation',
    3: 'Narration, monologue',
    4: 'Babbling',
    5: 'Speech synthesizer',
    6: 'Shout',
    7: 'Bellow',
    8: 'Whoop',
    9: 'Yell',
    10: 'Children shouting',
    11: 'Screaming',
    12: 'Whispering',
    13: 'Laughter',
    14: 'Baby laughter',
    15: 'Giggle',
    16: 'Snicker',
    17: 'Belly laugh',
    18: 'Chuckle, chortle',
    19: 'Crying, sobbing',
    20: 'Baby cry, infant cry',
    21: 'Whimper',
    22: 'Wail, moan',
    23: 'Sigh',
    24: 'Singing',
    25: 'Choir',
    26: 'Yodeling',
    27: 'Chant',
    28: 'Mantra',
    29: 'Child singing',
    30: 'Synthetic singing',
    31: 'Rapping',
    32: 'Humming',
    33: 'Groan',
    34: 'Grunt',
    35: 'Whistling',
    36: 'Breathing',
    37: 'Wheeze',
    38: 'Snoring',
    39: 'Gasp',
    40: 'Pant',
    41: 'Snort',
    42: 'Cough',
    43: 'Throat clearing',
    44: 'Sneeze',
    45: 'Sniff',
    46: 'Run, footsteps',
    47: 'Shuffle',
    48: 'Walk, footsteps',
    49: 'Chewing, mastication',
    50: 'Biting',
    51: 'Gargling',
    52: 'Stomach rumble',
    53: 'Burping, eructation',
    54: 'Hiccup',
    55: 'Fart',
    56: 'Hands',
    57: 'Finger snapping',
    58: 'Clapping',
    59: 'Heart sounds, heartbeat',
    60: 'Heart murmur',
    61: 'Cheering',
    62: 'Applause',
    63: 'Chatter',
    64: 'Crowd',
    65: 'Hubbub, speech noise, speech babble',
    66: 'Children playing',
    67: 'Animal',
    68: 'Domestic animals, pets',
    69: 'Dog',
    70: 'Bark',
    71: 'Yip',
    72: 'Howl',
    73: 'Bow-wow',
    74: 'Growling',
    75: 'Whimper (dog)',
    76: 'Cat',
    77: 'Meow',
    78: 'Purr',
    79: 'Feline growl',
    80: 'Hiss',
    81: 'Caterwaul',
    82: 'Livestock, farm animals, working animals',
    83: 'Horse',
    84: 'Clip-clop',
    85: 'Neigh, whinny',
    86: 'Cattle, bovinae',
    87: 'Moo',
    88: 'Pig',
    89: 'Oink',
    90: 'Goat',
    91: 'Bleat',
    92: 'Sheep',
    93: 'Fowl',
    94: 'Chicken, rooster',
    95: 'Cluck',
    96: 'Crowing, cock-a-doodle-doo',
    97: 'Turkey',
    98: 'Gobble',
    99: 'Duck',
    100: 'Quack',
    101: 'Goose',
    102: 'Honk',
    103: 'Rooster crowing',
    104: 'Pigeon, dove',
    105: 'Coo',
    106: 'Crow',
    107: 'Caw',
    108: 'Owl',
    109: 'Hoot',
    110: 'Bird',
    111: 'Squawk',
    112: 'Parrot',
    113: 'Chirp, tweet',
    114: 'Singing bird',
    115: 'Chirping bird',
    116: 'Squawk',
    117: 'Pigeon, dove',
    118: 'Crow',
    119: 'Owl',
    120: 'Wild animals',
    121: 'Cicada, chirp',
    122: 'Cricket',
    123: 'Grasshopper',
    124: 'Bee, wasp, etc.',
    125: 'Mosquito',
    126: 'Fly, housefly',
    127: 'Buzz',
    128: 'Frog',
    129: 'Croak',
    130: 'Snake',
    131: 'Rattle',
    132: 'Whale',
    133: 'Dolphin',
    134: 'Seal',
    135: 'Dog',
    136: 'Cat',
    137: 'Horse',
    138: 'Cattle, bovinae',
    139: 'Pig',
    140: 'Goat',
    141: 'Sheep',
    142: 'Chicken, rooster',
    143: 'Turkey',
    144: 'Duck',
    145: 'Goose',
    146: 'Pigeon, dove',
    147: 'Crow',
    148: 'Owl',
    149: 'Bird',
    150: 'Parrot',
    151: 'Cicada, chirp',
    152: 'Cricket',
    153: 'Grasshopper',
    154: 'Bee, wasp, etc.',
    155: 'Mosquito',
    156: 'Fly, housefly',
    157: 'Frog',
    158: 'Snake',
    159: 'Whale',
    160: 'Dolphin',
    161: 'Seal',
    162: 'Music',
    163: 'Musical instrument',
    164: 'Plucked string instrument',
    165: 'Guitar',
    166: 'Electric guitar',
    167: 'Bass guitar',
    168: 'Acoustic guitar',
    169: 'Steel guitar, slide guitar',
    170: 'Tapping (guitar technique)',
    171: 'Strum',
    172: 'Banjo',
    173: 'Sitar',
    174: 'Mandolin',
    175: 'Zither',
    176: 'Ukulele',
    177: 'Keyboard (musical)',
    178: 'Piano',
    179: 'Electric piano',
    180: 'Organ',
    181: 'Electronic organ',
    182: 'Hammond organ',
    183: 'Synthesizer',
    184: 'Sampler',
    185: 'Harpsichord',
    186: 'Percussion',
    187: 'Drum kit',
    188: 'Drum machine',
    189: 'Drum',
    190: 'Snare drum',
    191: 'Rimshot',
    192: 'Drum roll',
    193: 'Bass drum',
    194: 'Timpani',
    195: 'Tabla',
    196: 'Cymbal',
    197: 'Hi-hat',
    198: 'Crash cymbal',
    199: 'Ride cymbal',
    200: 'Splash cymbal',
    201: 'China cymbal',
    202: 'Bell',
    203: 'Jingle bell',
    204: 'Tuning fork',
    205: 'Chime',
    206: 'Wind chime',
    207: 'Change ringing (campanology)',
    208: 'Harmonica',
    209: 'Accordion',
    210: 'Bagpipes',
    211: 'Recorder',
    212: 'Oboe',
    213: 'Clarinet',
    214: 'Saxophone',
    215: 'Bassoon',
    216: 'French horn',
    217: 'Trumpet',
    218: 'Trombone',
    219: 'Tuba',
    220: 'Violin, fiddle',
    221: 'Viola',
    222: 'Cello',
    223: 'Double bass',
    224: 'Contrabassoon',
    225: 'Vibraphone',
    226: 'Xylophone',
    227: 'Marimba',
    228: 'Glockenspiel',
    229: 'Vibraphone',
    230: 'Steelpan',
    231: 'Tambourine',
    232: 'Castanets',
    233: 'Wood block',
    234: 'Claves',
    235: 'Whip',
    236: 'Music box',
    237: 'Kalimba',
    238: 'Bagpipes',
    239: 'Recorder',
    240: 'Oboe',
    241: 'Clarinet',
    242: 'Saxophone',
    243: 'Bassoon',
    244: 'French horn',
    245: 'Trumpet',
    246: 'Trombone',
    247: 'Tuba',
    248: 'Violin, fiddle',
    249: 'Viola',
    250: 'Cello',
    251: 'Double bass',
    252: 'Contrabassoon',
    253: 'Vibraphone',
    254: 'Xylophone',
    255: 'Marimba',
    256: 'Glockenspiel',
    257: 'Vibraphone',
    258: 'Steelpan',
    259: 'Tambourine',
    260: 'Castanets',
    261: 'Wood block',
    262: 'Claves',
    263: 'Whip',
    264: 'Music box',
    265: 'Kalimba',
    266: 'Bagpipes',
    267: 'Recorder',
    268: 'Oboe',
    269: 'Clarinet',
    270: 'Saxophone',
    271: 'Bassoon',
    272: 'French horn',
    273: 'Trumpet',
    274: 'Trombone',
    275: 'Tuba',
    276: 'Violin, fiddle',
    277: 'Viola',
    278: 'Cello',
    279: 'Double bass',
    280: 'Contrabassoon',
    281: 'Vibraphone',
    282: 'Xylophone',
    283: 'Marimba',
    284: 'Glockenspiel',
    285: 'Vibraphone',
    286: 'Steelpan',
    287: 'Tambourine',
    288: 'Castanets',
    289: 'Wood block',
    290: 'Claves',
    291: 'Whip',
    292: 'Music box',
    293: 'Kalimba',
    294: 'Bagpipes',
    295: 'Recorder',
    296: 'Oboe',
    297: 'Clarinet',
    298: 'Saxophone',
    299: 'Bassoon',
    300: 'French horn',
    301: 'Trumpet',
    302: 'Trombone',
    303: 'Tuba',
    304: 'Violin, fiddle',
    305: 'Viola',
    306: 'Cello',
    307: 'Double bass',
    308: 'Contrabassoon',
    309: 'Vibraphone',
    310: 'Xylophone',
    311: 'Marimba',
    312: 'Glockenspiel',
    313: 'Vibraphone',
    314: 'Steelpan',
    315: 'Tambourine',
    316: 'Castanets',
    317: 'Wood block',
    318: 'Claves',
    319: 'Whip',
    320: 'Music box',
    321: 'Kalimba',
    322: 'Bagpipes',
    323: 'Recorder',
    324: 'Oboe',
    325: 'Clarinet',
    326: 'Saxophone',
    327: 'Bassoon',
    328: 'French horn',
    329: 'Trumpet',
    330: 'Trombone',
    331: 'Tuba',
    332: 'Violin, fiddle',
    333: 'Viola',
    334: 'Cello',
    335: 'Double bass',
    336: 'Contrabassoon',
    337: 'Vibraphone',
    338: 'Xylophone',
    339: 'Marimba',
    340: 'Glockenspiel',
    341: 'Vibraphone',
    342: 'Steelpan',
    343: 'Tambourine',
    344: 'Castanets',
    345: 'Wood block',
    346: 'Claves',
    347: 'Whip',
    348: 'Music box',
    349: 'Kalimba',
    350: 'Bagpipes',
    351: 'Recorder',
    352: 'Oboe',
    353: 'Clarinet',
    354: 'Saxophone',
    355: 'Bassoon',
    356: 'French horn',
    357: 'Trumpet',
    358: 'Trombone',
    359: 'Tuba',
    360: 'Violin, fiddle',
    361: 'Viola',
    362: 'Cello',
    363: 'Double bass',
    364: 'Contrabassoon',
    365: 'Vibraphone',
    366: 'Xylophone',
    367: 'Marimba',
    368: 'Glockenspiel',
    369: 'Vibraphone',
    370: 'Steelpan',
    371: 'Tambourine',
    372: 'Castanets',
    373: 'Wood block',
    374: 'Claves',
    375: 'Whip',
    376: 'Music box',
    377: 'Kalimba',
    378: 'Bagpipes',
    379: 'Recorder',
    380: 'Oboe',
    381: 'Clarinet',
    382: 'Saxophone',
    383: 'Bassoon',
    384: 'French horn',
    385: 'Trumpet',
    386: 'Trombone',
    387: 'Tuba',
    388: 'Violin, fiddle',
    389: 'Viola',
    390: 'Cello',
    391: 'Double bass',
    392: 'Contrabassoon',
    393: 'Vibraphone',
    394: 'Xylophone',
    395: 'Marimba',
    396: 'Glockenspiel',
    397: 'Vibraphone',
    398: 'Steelpan',
    399: 'Tambourine',
    400: 'Castanets',
    401: 'Wood block',
    402: 'Claves',
    403: 'Whip',
    404: 'Music box',
    405: 'Kalimba',
    406: 'Recorder',
    407: 'Oboe',
    408: 'Clarinet',
    409: 'Saxophone',
    410: 'Bassoon',
    411: 'French horn',
    412: 'Trumpet',
    413: 'Trombone',
    414: 'Tuba',
    415: 'Violin, fiddle',
    416: 'Viola',
    417: 'Cello',
    418: 'Double bass',
    419: 'Contrabassoon',
    420: 'Vibraphone',
    421: 'Xylophone',
    422: 'Marimba',
    423: 'Glockenspiel',
    424: 'Vibraphone',
    425: 'Steelpan',
    426: 'Tambourine',
    427: 'Castanets',
    428: 'Wood block',
    429: 'Claves',
    430: 'Whip',
    431: 'Music box',
    432: 'Kalimba',
    433: 'Bagpipes',
    434: 'Recorder',
    435: 'Oboe',
    436: 'Clarinet',
    437: 'Saxophone',
    438: 'Bassoon',
    439: 'French horn',
    440: 'Trumpet',
    441: 'Trombone',
    442: 'Tuba',
    443: 'Violin, fiddle',
    444: 'Viola',
    445: 'Cello',
    446: 'Double bass',
    447: 'Contrabassoon',
    448: 'Vibraphone',
    449: 'Xylophone',
    450: 'Marimba',
    451: 'Glockenspiel',
    452: 'Vibraphone',
    453: 'Steelpan',
    454: 'Tambourine',
    455: 'Castanets',
    456: 'Wood block',
    457: 'Claves',
    458: 'Whip',
    459: 'Music box',
    460: 'Kalimba',
    461: 'Bagpipes',
    462: 'Recorder',
    463: 'Oboe',
    464: 'Clarinet',
    465: 'Saxophone',
    466: 'Bassoon',
    467: 'French horn',
    468: 'Trumpet',
    469: 'Trombone',
    470: 'Tuba',
    471: 'Violin, fiddle',
    472: 'Viola',
    473: 'Cello',
    474: 'Double bass',
    475: 'Contrabassoon',
    476: 'Vibraphone',
    477: 'Xylophone',
    478: 'Marimba',
    479: 'Glockenspiel',
    480: 'Vibraphone',
    481: 'Steelpan',
    482: 'Tambourine',
    483: 'Castanets',
    484: 'Wood block',
    485: 'Claves',
    486: 'Whip',
    487: 'Music box',
    488: 'Kalimba',
    489: 'Bagpipes',
    490: 'Recorder',
    491: 'Oboe',
    492: 'Clarinet',
    493: 'Saxophone',
    494: 'Bassoon',
    495: 'French horn',
    496: 'Trumpet',
    497: 'Trombone',
    498: 'Tuba',
    499: 'Violin, fiddle',
    500: 'Viola',
    501: 'Cello',
    502: 'Double bass',
    503: 'Contrabassoon',
    504: 'Vibraphone',
    505: 'Xylophone',
    506: 'Marimba',
    507: 'Glockenspiel',
    508: 'Vibraphone',
    509: 'Steelpan',
    510: 'Tambourine',
    511: 'Castanets',
    512: 'Wood block',
    513: 'Claves',
    514: 'Whip',
    515: 'Music box',
    516: 'Kalimba',
    517: 'Bagpipes',
    518: 'Recorder',
    519: 'Oboe',
    520: 'Clarinet',
    521: 'Saxophone'
  };
  
  return labels[index] || `Unknown (${index})`;
}

function extractInstruments(topClasses: any[]): string[] {
  const instrumentKeywords = [
    'guitar', 'piano', 'violin', 'drum', 'bass', 'saxophone', 'trumpet', 'flute',
    'clarinet', 'oboe', 'bassoon', 'trombone', 'tuba', 'organ', 'synthesizer',
    'harmonica', 'accordion', 'bagpipes', 'recorder', 'cello', 'viola', 'double bass',
    'vibraphone', 'xylophone', 'marimba', 'glockenspiel', 'steelpan', 'tambourine',
    'castanets', 'wood block', 'claves', 'whip', 'music box', 'kalimba'
  ];
  
  return topClasses
    .filter(cls => instrumentKeywords.some(keyword => 
      cls.label.toLowerCase().includes(keyword)
    ))
    .map(cls => cls.label);
}

function extractEvents(topClasses: any[]): string[] {
  const eventKeywords = [
    'speech', 'singing', 'laughter', 'crying', 'applause', 'cheering', 'clapping',
    'footsteps', 'breathing', 'coughing', 'sneezing', 'snoring', 'whistling',
    'animal', 'bird', 'dog', 'cat', 'horse', 'cow', 'pig', 'chicken', 'duck'
  ];
  
  return topClasses
    .filter(cls => eventKeywords.some(keyword => 
      cls.label.toLowerCase().includes(keyword)
    ))
    .map(cls => cls.label);
}

// å¼¹å¹•ç”Ÿæˆå‡½æ•°
function generateDanmuMessage(features: any, yamnetResults: any): string {
  const messages = [];
  
  // åŸºäºéŸ³é¢‘ç‰¹å¾ç”Ÿæˆå¼¹å¹•
  if (features) {
    const { rms, spectralCentroid, zcr, voiceProb, percussiveRatio, harmonicRatio } = features;
    
    // éŸ³é‡ç›¸å…³
    if (rms > 0.7) {
      messages.push('éŸ³é‡å¾ˆå¤§ï¼', 'å¾ˆæœ‰åŠ›é‡ï¼', 'éœ‡æ’¼ï¼');
    } else if (rms > 0.4) {
      messages.push('éŸ³é‡é€‚ä¸­', 'å¬èµ·æ¥ä¸é”™', 'å¾ˆå¥½å¬');
    } else if (rms > 0.1) {
      messages.push('éŸ³é‡è¾ƒå°', 'å¾ˆè½»æŸ”', 'å®‰é™çš„æ„Ÿè§‰');
    }
    
    // éŸ³è‰²ç›¸å…³
    if (spectralCentroid > 2000) {
      messages.push('éŸ³è‰²å¾ˆäº®', 'é«˜éŸ³å¾ˆæ¸…æ™°', 'å¾ˆæ¸…è„†');
    } else if (spectralCentroid < 800) {
      messages.push('éŸ³è‰²å¾ˆæš–', 'ä½éŸ³å¾ˆä¸°å¯Œ', 'å¾ˆæ¸©æš–');
    }
    
    // äººå£°ç›¸å…³
    if (voiceProb > 0.7) {
      messages.push('äººå£°å¾ˆæ¸…æ™°', 'å”±å¾—å¾ˆå¥½', 'å£°éŸ³å¾ˆæ£’');
    } else if (voiceProb < 0.3) {
      messages.push('çº¯éŸ³ä¹', 'æ²¡æœ‰æ­Œè¯', 'å™¨ä¹æ¼”å¥');
    }
    
    // èŠ‚å¥ç›¸å…³
    if (percussiveRatio > 0.6) {
      messages.push('èŠ‚å¥æ„Ÿå¾ˆå¼º', 'å¾ˆæœ‰èŠ‚æ‹', 'å¾ˆåŠ¨æ„Ÿ');
    } else if (harmonicRatio > 0.6) {
      messages.push('å’Œå£°å¾ˆç¾', 'å¾ˆå’Œè°', 'æ—‹å¾‹ä¼˜ç¾');
    }
  }
  
  // åŸºäºYAMNetåˆ†ç±»ç”Ÿæˆå¼¹å¹•
  if (yamnetResults && yamnetResults.instruments.length > 0) {
    const instruments = yamnetResults.instruments;
    if (instruments.some((inst: string) => inst.toLowerCase().includes('guitar'))) {
      messages.push('å‰ä»–å¾ˆå¥½å¬', 'å‰ä»–æ¼”å¥å¾ˆæ£’', 'å–œæ¬¢è¿™ä¸ªå‰ä»–');
    }
    if (instruments.some((inst: string) => inst.toLowerCase().includes('piano'))) {
      messages.push('é’¢ç´å¾ˆä¼˜ç¾', 'é’¢ç´æ¼”å¥å¾ˆæ£’', 'å–œæ¬¢è¿™ä¸ªé’¢ç´');
    }
    if (instruments.some((inst: string) => inst.toLowerCase().includes('drum'))) {
      messages.push('é¼“ç‚¹å¾ˆæ£’', 'èŠ‚å¥å¾ˆå¥½', 'å¾ˆæœ‰èŠ‚æ‹æ„Ÿ');
    }
    if (instruments.some((inst: string) => inst.toLowerCase().includes('violin'))) {
      messages.push('å°æç´å¾ˆä¼˜ç¾', 'å¼¦ä¹å¾ˆæ£’', 'å¾ˆä¼˜é›…');
    }
  }
  
  // åŸºäºäº‹ä»¶ç”Ÿæˆå¼¹å¹•
  if (yamnetResults && yamnetResults.events.length > 0) {
    const events = yamnetResults.events;
    if (events.some((event: string) => event.toLowerCase().includes('singing'))) {
      messages.push('å”±å¾—å¾ˆå¥½', 'æ­Œå£°å¾ˆç¾', 'å¾ˆæœ‰æ„Ÿæƒ…');
    }
    if (events.some((event: string) => event.toLowerCase().includes('applause'))) {
      messages.push('æŒå£°ï¼', 'å¤ªæ£’äº†ï¼', 'ç²¾å½©ï¼');
    }
  }
  
  // é»˜è®¤å¼¹å¹•
  if (messages.length === 0) {
    messages.push('å¾ˆå¥½å¬', 'ä¸é”™', 'å¾ˆæ£’', 'å–œæ¬¢è¿™ä¸ª', 'ç»§ç»­æ’­æ”¾');
  }
  
  // éšæœºé€‰æ‹©ä¸€ä¸ªæ¶ˆæ¯
  return messages[Math.floor(Math.random() * messages.length)];
}

// å­—ç´ ç°‡æ‹†åˆ†å‡½æ•° - æ”¯æŒä¸­æ–‡ã€emojiç­‰å¤æ‚å­—ç¬¦
function segmentGraphemes(input: string): string[] {
  try {
    if ((Intl as any)?.Segmenter) {
      const seg = new (Intl as any).Segmenter(undefined, { granularity: 'grapheme' });
      return Array.from(seg.segment(input), (s: any) => s.segment);
    }
  } catch (_) {
    // é™çº§æ–¹æ¡ˆï¼šç®€å•å­—ç¬¦æ‹†åˆ†
  }
  return Array.from(input);
}

// FlipOption ç»„ä»¶
interface FlipOptionProps {
  label: string;
  selected?: boolean;
  disabled?: boolean;
  onSelect?: () => void;
  density?: 'compact' | 'normal' | 'spacious';
  animation?: 'auto' | 'reduced' | 'off';
  className?: string;
}

const FlipOption: React.FC<FlipOptionProps> = ({
  label,
  selected = false,
  disabled = false,
  onSelect,
  density = 'normal',
  animation = 'auto',
  className = ''
}) => {
  const handleClick = useCallback(() => {
    if (!disabled && onSelect) {
      onSelect();
    }
  }, [disabled, onSelect]);

  const handleKeyDown = useCallback((e: React.KeyboardEvent) => {
    if (e.key === 'Enter' || e.key === ' ') {
      e.preventDefault();
      handleClick();
    }
  }, [handleClick]);

  const sizeClasses = {
    compact: 'text-xl sm:text-2xl',
    normal: 'text-2xl sm:text-4xl md:text-6xl',
    spacious: 'text-4xl sm:text-6xl md:text-8xl'
  };

  const colorClasses = selected 
    ? 'text-cyan-400 group-hover:text-cyan-300' 
    : 'text-purple-400 group-hover:text-purple-300';

  const disabledClasses = disabled 
    ? 'opacity-50 cursor-not-allowed' 
    : 'cursor-pointer';

  const graphemes = segmentGraphemes(label);
  const centerIndex = (graphemes.length - 1) / 2;

  return (
    <button
      onClick={handleClick}
      onKeyDown={handleKeyDown}
      disabled={disabled}
      className={`
        group relative block overflow-hidden whitespace-nowrap
        ${sizeClasses[density]}
        ${colorClasses}
        ${disabledClasses}
        font-black uppercase
        focus:outline-none focus:ring-2 focus:ring-cyan-400 focus:ring-offset-2 focus:ring-offset-black
        min-h-[44px] min-w-[44px]
        ${className}
      `}
      style={{
        lineHeight: 0.75,
      }}
      role="option"
      aria-selected={selected}
      aria-disabled={disabled}
      tabIndex={disabled ? -1 : 0}
    >
      {/* ä¸Šå±‚æ–‡å­— - æ‚¬åœæ—¶å‘ä¸Šç§»åŠ¨ */}
      <div className="flex">
        {graphemes.map((grapheme, i) => (
          <span
            key={`top-${i}`}
            className={`inline-block transition-transform duration-300 ease-in-out group-hover:-translate-y-[110%] ${selected ? '-translate-y-[180%] opacity-0' : ''}`}
            style={{
              transitionDelay: `${Math.abs(i - centerIndex) * 25}ms`,
            }}
          >
            {grapheme}
          </span>
        ))}
      </div>
      
      {/* ä¸‹å±‚æ–‡å­— - æ‚¬åœæ—¶ä»ä¸‹æ–¹æ»‘å…¥ */}
      <div className="absolute inset-0 flex">
        {graphemes.map((grapheme, i) => (
          <span
            key={`bottom-${i}`}
            className={`inline-block transition-transform duration-300 ease-in-out translate-y-[180%] group-hover:translate-y-0 opacity-0 group-hover:opacity-100 ${selected ? 'translate-y-0 opacity-100' : 'pointer-events-none'}`}
            style={{
              transitionDelay: `${Math.abs(i - centerIndex) * 25}ms`,
            }}
          >
            {grapheme}
          </span>
        ))}
      </div>

      {/* é€‰ä¸­çŠ¶æ€æŒ‡ç¤ºå™¨ */}
      {selected && (
        <div className="absolute -bottom-1 left-0 right-0 h-1 bg-cyan-400 rounded-full" />
      )}
    </button>
  );
};

// é¢„è®¾é€‰é¡¹é…ç½®ï¼ˆç§»åŠ¨ç«¯ä½¿ç”¨ä¸¤å­—æ¯ç¼©å†™å±•ç¤ºï¼‰
const PRESET_OPTIONS = [
  { id: 'wave', label: 'Wave', abbrMobile: 'WA' },
  { id: 'accretion', label: 'Accretion', abbrMobile: 'AC' },
  { id: 'spiral', label: 'Spiral', abbrMobile: 'SP' },
  { id: 'mosaic', label: 'Mosaic', abbrMobile: 'MO' }
];

export default function StandaloneClient() {
  // çŠ¶æ€ç®¡ç†
  const [currentPreset, setCurrentPreset] = useState<string>('wave');
  const [animationMode, setAnimationMode] = useState<'auto' | 'reduced' | 'off'>('auto');
  const [isRunning, setIsRunning] = useState(false);
  const [audioLevel, setAudioLevel] = useState(0);
  const [features, setFeatures] = useState(null);
  const [sensitivity, setSensitivity] = useState(1.5);
  const [yamnetResults, setYamnetResults] = useState(null); // YAMNet classification results
  const [danmuEnabled, setDanmuEnabled] = useState(false); // Danmu toggle state
  const [microphoneEnabled, setMicrophoneEnabled] = useState(false); // Microphone toggle state
  const [spectrumPriority, setSpectrumPriority] = useState(() => {
    try {
      const env = (process as any)?.env || (window as any)?.process?.env || {};
      const v = env.NEXT_PUBLIC_SPECTRUM_PRIORITY;
      return String(v ?? 'true') !== 'false';
    } catch (_) { return true; }
  }); // é¢‘è°±ä¼˜å…ˆæ¨¡å¼ï¼ˆenv å¯è¦†ç›–ï¼‰
  
  // LLMå¼¹å¹•ç®¡çº¿é›†æˆ
  const danmuPipeline = useDanmuPipeline({
    autoStart: false, // æ‰‹åŠ¨æ§åˆ¶å¯åŠ¨
    useSimple: false, // ä½¿ç”¨å¢å¼ºç‰ˆç®¡çº¿ï¼ˆå®Œæ•´LLMåŠŸèƒ½ï¼‰
    // è°ƒæ•´ä¸ºæ¯æ¬¡ç”Ÿæˆ5æ¡åŸºç¡€å¼¹å¹•ï¼ˆé¼“åŠ±/é™ªä¼´å‹é¢å¤–åœ¨ç®¡çº¿å†…è¿½åŠ 1-2æ¡ï¼‰
    needComments: 5, // æ¯æ¬¡ç”Ÿæˆ5æ¡å¼¹å¹•
    locale: 'zh-CN',
    minIntervalMs: 3000, // æœ€å°é—´éš”3ç§’
    maxConcurrency: 1, // æœ€å¤§å¹¶å‘1ä¸ªè¯·æ±‚
    rmsThreshold: 0.01, // RMSé˜ˆå€¼
    requireStability: true, // éœ€è¦ç¨³å®šæ€§æ£€æµ‹
    stabilityWindowMs: 2000, // ç¨³å®šæ€§çª—å£2ç§’
    stabilityConfidence: 0.4, // ç¨³å®šæ€§ç½®ä¿¡åº¦
  });
  
  // ä½¿ç”¨ useRef æ¥ç¡®ä¿å¼‚æ­¥å›è°ƒèƒ½å¤Ÿè®¿é—®åˆ°æœ€æ–°çš„å¼¹å¹•ç®¡çº¿çŠ¶æ€
  const danmuPipelineRef = useRef(danmuPipeline);
  danmuPipelineRef.current = danmuPipeline;
  
  // è°ƒè¯•é¢æ¿æ˜¾ç¤ºï¼šé¿å… SSR/CSR åˆå§‹ä¸ä¸€è‡´ï¼ŒæŒ‚è½½åå†å†³å®š
  const [debugVisible, setDebugVisible] = useState<boolean>(false);
  const [debugInfo, setDebugInfo] = useState<{ ctxState: string; sampleRate: number; hasStream: boolean; hasAnalyser: boolean; rms: number; maxAbs: number; zeroCount: number; lastSamples: number[]; isSecure: boolean; hasMedia: boolean; micPermission: string; lastError?: string }>({
    ctxState: 'unknown', sampleRate: 0, hasStream: false, hasAnalyser: false, rms: 0, maxAbs: 0, zeroCount: 0, lastSamples: [],
    isSecure: typeof window !== 'undefined' ? !!(window as any).isSecureContext : false,
    hasMedia: typeof navigator !== 'undefined' ? !!navigator.mediaDevices : false,
    micPermission: 'unknown'
  });
  // è°ƒè¯•é¢æ¿é•¿æŒ‰è§¦å‘å¼•ç”¨
  const longPressTimerRef = useRef<number | null>(null);
  const longPressStartRef = useRef<number>(0);
  const [embedInfo, setEmbedInfo] = useState<{ inIframe: boolean; policyMicrophone?: string; policyCamera?: string }>({ inIframe: false });
  // ä¸€æ¬¡æ€§å¯åŠ¨æ ‡è®°ï¼Œé¿å…é‡å¤è§¦å‘
  const micStartedRef = useRef<boolean>(false);
  
  // éŸ³é¢‘å¤„ç†å¼•ç”¨
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const sourceRef = useRef<MediaStreamAudioSourceNode | null>(null);
  const gainRef = useRef<GainNode | null>(null);
  const dataArrayRef = useRef<Uint8Array | null>(null);
  const animationFrameRef = useRef<number | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const meydaAnalyzerRef = useRef<any | null>(null); // Meyda analyzer reference
  const yamnetModelRef = useRef<any | null>(null); // YAMNet model referenceï¼ˆåŠ¨æ€åŠ è½½ TFJS åç»Ÿä¸€ anyï¼‰
  const yamnetBufferRef = useRef<Float32Array | null>(null); // Audio buffer for YAMNet
  // è½»é‡ BPM çŠ¶æ€ï¼šåŸºäº onset é—´éš”çš„æ»‘çª—ä¼°è®¡
  const bpmStateRef = useRef<{ lastOnsetSec: number; intervals: number[]; bpm: number; confidence: number }>({
    lastOnsetSec: 0,
    intervals: [],
    bpm: 0,
    confidence: 0,
  });
  // é¢‘è°±åˆ—å¹³æ»‘ç¼“å­˜
  const bandColumnsRef = useRef<number[] | null>(null);
  // MEL é¢‘è°±é…ç½®ä¸å†å²
  const melConfigRef = useRef<{ binMap: number[]; cols: number; minHz: number; maxHz: number } | null>(null);
  const spectrumHistoryRef = useRef<Array<{
    level: { instant: number; slow: number };
    bands: { low: { instant: number; slow: number }; mid: { instant: number; slow: number }; high: { instant: number; slow: number } };
    columns: Float32Array;
    columnsSmooth: Float32Array;
  }>>([]);
  const spectrumStateRef = useRef<{
    levelSlow: number;
    lowSlow: number; midSlow: number; highSlow: number;
    columnsSlow?: Float32Array;
  }>({ levelSlow: 0, lowSlow: 0, midSlow: 0, highSlow: 0 });
  // FPS è‡ªé€‚åº”
  const fpsStateRef = useRef<{ lastTs: number; frames: number; fps: number }>({ lastTs: (typeof performance !== 'undefined' ? performance.now() : Date.now()), frames: 0, fps: 60 });
  const melDesiredColsRef = useRef<number | null>(null);
  const spectrumUpdateDividerRef = useRef<number>(1);
  // èŠ‚æ‹ç›¸ä½åŒæ­¥
  const tempoPhaseRef = useRef<{ phase: number; lastTime: number }>({ phase: 0, lastTime: 0 });
  // è½»é‡éŸ³é«˜ä¸èµ·éŸ³æ£€æµ‹çŠ¶æ€
  const pitchStateRef = useRef<{ lastHz: number; smoothHz: number; confidence: number; frame: number }>({ lastHz: 0, smoothHz: 0, confidence: 0, frame: 0 });
  const onsetStateRef = useRef<{ armed: boolean; lastOnsetSec: number }>({ armed: true, lastOnsetSec: 0 });

  // åˆ‡æ¢å¼¹å¹•å¼€å…³
  const toggleDanmu = useCallback((next?: boolean) => {
    try {
      const enable = typeof next === 'boolean' ? next : !danmuEnabled;
      setDanmuEnabled(enable);

      const currentPipeline = danmuPipelineRef.current;
      if (currentPipeline.isReady) {
        if (enable) {
          currentPipeline.start();
          console.log('ğŸµ LLMå¼¹å¹•ç®¡çº¿å·²å¯åŠ¨');
        } else {
          currentPipeline.stop();
          console.log('ğŸµ LLMå¼¹å¹•ç®¡çº¿å·²åœæ­¢');
          // æ¸…ç†å±å¹•ä¸Šå·²æœ‰å¼¹å¹•å…ƒç´ 
          const container = document.getElementById('danmu-container');
          if (container) {
            try {
              container.innerHTML = '';
            } catch (_) {}
          }
        }
      } else {
        console.log('ğŸµ LLMå¼¹å¹•ç®¡çº¿æœªå°±ç»ªï¼Œç­‰å¾…åˆå§‹åŒ–å®Œæˆ...');
        // ç­‰å¾…å¼¹å¹•ç®¡çº¿åˆå§‹åŒ–å®Œæˆ
        let attempts = 0;
        const maxAttempts = 50; // æœ€å¤šç­‰å¾…5ç§’
        const checkReady = () => {
          attempts++;
          // ä½¿ç”¨ ref è·å–æœ€æ–°çŠ¶æ€
          const currentPipeline = danmuPipelineRef.current;
          console.log(`ğŸµ æ£€æŸ¥å¼¹å¹•ç®¡çº¿çŠ¶æ€ (${attempts}/${maxAttempts}):`, {
            isReady: currentPipeline.isReady,
            isActive: currentPipeline.isActive,
            danmuCount: currentPipeline.danmuCount
          });
          
          if (currentPipeline.isReady || currentPipeline.isActive) {
            if (enable && !currentPipeline.isActive) {
              currentPipeline.start();
              console.log('ğŸµ LLMå¼¹å¹•ç®¡çº¿å·²å¯åŠ¨ï¼ˆå»¶è¿Ÿå¯åŠ¨ï¼‰');
            } else if (currentPipeline.isActive) {
              console.log('ğŸµ LLMå¼¹å¹•ç®¡çº¿å·²ç»å¯åŠ¨ï¼Œæ— éœ€é‡å¤å¯åŠ¨');
            }
            // æ‰¾åˆ°çŠ¶æ€ï¼Œé€€å‡ºæ£€æŸ¥
            return;
          } else if (attempts < maxAttempts) {
            // ç»§ç»­ç­‰å¾…
            setTimeout(checkReady, 100);
          } else {
            console.warn('ğŸµ å¼¹å¹•ç®¡çº¿åˆå§‹åŒ–è¶…æ—¶ï¼Œæ— æ³•å¯åŠ¨');
          }
        };
        setTimeout(checkReady, 100);
      }
    } catch (err) {
      console.warn('åˆ‡æ¢LLMå¼¹å¹•å¤±è´¥:', err);
    }
  }, [danmuEnabled, danmuPipeline]);

  // å½“å¼¹å¹•ç®¡çº¿åˆå§‹åŒ–å®Œæˆä¸”å¼¹å¹•å¼€å…³å¼€å¯æ—¶ï¼Œè‡ªåŠ¨å¯åŠ¨
  useEffect(() => {
    const currentPipeline = danmuPipelineRef.current;
    if (currentPipeline.isReady && danmuEnabled && !currentPipeline.isActive) {
      console.log('ğŸµ å¼¹å¹•ç®¡çº¿åˆå§‹åŒ–å®Œæˆï¼Œè‡ªåŠ¨å¯åŠ¨...');
      currentPipeline.start();
    } else if (currentPipeline.isActive) {
      console.log('ğŸµ å¼¹å¹•ç®¡çº¿å·²ç»å¯åŠ¨ï¼Œæ— éœ€é‡å¤å¯åŠ¨');
    }
  }, [danmuPipeline.isReady, danmuEnabled, danmuPipeline.isActive]);

  // æ£€æµ‹ç”¨æˆ·åå¥½
  useEffect(() => {
    const mediaQuery = typeof window !== 'undefined' ? window.matchMedia('(prefers-reduced-motion: reduce)') : null;
    if (mediaQuery && mediaQuery.matches) {
      setAnimationMode('reduced');
    }
    
    if (mediaQuery) {
      const handleChange = (e: MediaQueryListEvent) => {
        setAnimationMode(e.matches ? 'reduced' : 'auto');
      };
      
      mediaQuery.addEventListener('change', handleChange);
      return () => mediaQuery.removeEventListener('change', handleChange);
    }
  }, []);

  // éŸ³é¢‘åˆ†æå¾ªç¯ - ä½¿ç”¨Meydaè¿›è¡ŒçœŸå®ç‰¹å¾æå–
  const analyzeAudio = useCallback(() => {
    if (!analyserRef.current) return;

    const analyser = analyserRef.current;
    const bufferLength = analyser.fftSize;
    const timeDomainData = new Float32Array(bufferLength);

    // ä½¿ç”¨æ—¶åŸŸæ•°æ®è®¡ç®— RMS ä¸å³°å€¼
    analyser.getFloatTimeDomainData(timeDomainData);

    let sumSquares = 0;
    let maxAbs = 0;
    let minVal = 1;
    let maxVal = -1;
    let zeroCount = 0;

    for (let i = 0; i < bufferLength; i++) {
      const sample = timeDomainData[i]; // [-1, 1]
      if (sample === 0) zeroCount++;
      sumSquares += sample * sample;
      if (sample > maxVal) maxVal = sample;
      if (sample < minVal) minVal = sample;
      const abs = Math.abs(sample);
      if (abs > maxAbs) maxAbs = abs;
    }

    const rms = Math.sqrt(sumSquares / bufferLength); // [0, 1]
    let normalizedLevel = Math.min(Math.max(rms, 0), 1);

    // è°ƒè¯•ä¿¡æ¯ï¼šæ£€æŸ¥æ˜¯å¦æ‰€æœ‰å€¼éƒ½æ˜¯0
    if (zeroCount === bufferLength) {
      console.warn('âš ï¸ éŸ³é¢‘æ•°æ®å…¨ä¸ºé›¶ - å¯èƒ½éŸ³é¢‘æµæœªæ­£ç¡®è¿æ¥');
      const sampleValues = Array.from(timeDomainData.slice(0, 10));
      console.log('å‰10ä¸ªéŸ³é¢‘æ ·æœ¬å€¼:', sampleValues);
    }

    setAudioLevel(normalizedLevel);
    // ä½é¢‘ç‡æ›´æ–°è°ƒè¯•é¢æ¿ï¼Œé¿å…é«˜é¢‘ setState é€ æˆæ€§èƒ½é—®é¢˜
    try {
      if (Math.random() < 0.1) {
        setDebugInfo(prev => ({
          ...prev,
          ctxState: audioContextRef.current?.state || 'unknown',
          sampleRate: audioContextRef.current?.sampleRate || 0,
          hasStream: !!streamRef.current,
          hasAnalyser: !!analyserRef.current,
          rms,
          maxAbs,
          zeroCount,
          lastSamples: Array.from(timeDomainData.slice(0, 8))
        }));
      }
    } catch (e) {
      console.warn('æ›´æ–°è°ƒè¯•ä¿¡æ¯å¤±è´¥:', e);
    }
    
    // è°ƒè¯•æ—¥å¿— - æ¯100å¸§è¾“å‡ºä¸€æ¬¡
    if (Math.random() < 0.01) {
      console.log('éŸ³é¢‘çº§åˆ«:', normalizedLevel.toFixed(3), 'RMS:', rms.toFixed(3), 'MaxAbs:', maxAbs.toFixed(3), 'ZeroCount:', zeroCount, 'BufferLength:', bufferLength);
    }
    
    // ç»§ç»­å¾ªç¯
    animationFrameRef.current = requestAnimationFrame(analyzeAudio);
  }, []);

  // å¯åŠ¨éŸ³é¢‘å¤„ç† - å‚è€ƒä¸»é¡µé¢çš„å®ç°
  const startAudioProcessing = useCallback(async () => {
    try {
      console.log('è¯·æ±‚éº¦å…‹é£æƒé™...');

      // è·å–éº¦å…‹é£æƒé™
      let stream: MediaStream | null = null;
      try {
        stream = await navigator.mediaDevices.getUserMedia({
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
          }
        });
      } catch (primaryErr) {
        console.warn('å¸¦çº¦æŸçš„ getUserMedia å¤±è´¥ï¼Œé€€åŒ–ä¸º audio: true', primaryErr);
        // æŸäº›ç§»åŠ¨ç«¯æµè§ˆå™¨ä¸æ”¯æŒä¸Šè¿°çº¦æŸï¼Œå›é€€ä¸ºæœ€ç®€çº¦æŸ
        try {
          stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        } catch (fallbackErr) {
          try { setDebugInfo(prev => ({ ...prev, lastError: String(fallbackErr) })); } catch (_) {}
          throw fallbackErr;
        }
      }

      console.log('åˆ›å»ºéŸ³é¢‘ä¸Šä¸‹æ–‡...');

      // åˆ›å»ºéŸ³é¢‘ä¸Šä¸‹æ–‡
      // åœ¨ iOS/Safari ä¸Šï¼ŒAudioContext éœ€è¦åœ¨ç”¨æˆ·æ‰‹åŠ¿å resume
      const AudioContextCtor = typeof window !== 'undefined' ? ((window as any).AudioContext || (window as any).webkitAudioContext) : null;
      if (!AudioContextCtor) {
        throw new Error('AudioContext not supported');
      }
      const audioContext = new AudioContextCtor({ latencyHint: 'interactive' });
      const analyser = audioContext.createAnalyser();
      const source = audioContext.createMediaStreamSource(stream!);
      sourceRef.current = source;

      // é…ç½®åˆ†æå™¨ - ä½¿ç”¨ä¸ä¸»é¡µé¢ç›¸åŒçš„é…ç½®
      analyser.fftSize = 2048; // ä¸ä¸»é¡µé¢ä¸€è‡´
      analyser.smoothingTimeConstant = 0.5; // ä¸ä¸»é¡µé¢ä¸€è‡´

      // è¿æ¥éŸ³é¢‘èŠ‚ç‚¹
      source.connect(analyser);
      // ä¸ºé¿å… Safari åœ¨æœªè¿å‘è¾“å‡ºæ—¶ä¼˜åŒ–æ‰éŸ³é¢‘å›¾ï¼ˆå¯¼è‡´æ•°æ®å…¨ 0ï¼‰ï¼Œ
      // æˆ‘ä»¬å°† analyser é€šè¿‡ 0 å¢ç›Šçš„ GainNode æ¥åˆ° destinationï¼Œ
      // ä¸äº§ç”Ÿå›æ”¾ä½†ä¿æŒéŸ³é¢‘å›¾æ´»è·ƒã€‚
      try {
        const silentGain = audioContext.createGain();
        silentGain.gain.value = 0;
        analyser.connect(silentGain);
        silentGain.connect(audioContext.destination);
        gainRef.current = silentGain;
      } catch (chainErr) {
        console.warn('è¿æ¥é™éŸ³å¢ç›ŠèŠ‚ç‚¹å¤±è´¥ï¼ˆå¯å¿½ç•¥ï¼‰:', chainErr);
      }
      
      // è°ƒè¯•ï¼šæ£€æŸ¥è¿æ¥çŠ¶æ€
      console.log('éŸ³é¢‘èŠ‚ç‚¹è¿æ¥çŠ¶æ€:', {
        sourceConnected: source.context.state,
        analyserConnected: analyser.context.state,
        analyserFftSize: analyser.fftSize,
        analyserFrequencyBinCount: analyser.frequencyBinCount
      });

      // ç¡®ä¿éŸ³é¢‘ä¸Šä¸‹æ–‡è¿è¡Œ
      try {
        if (audioContext.state !== 'running') {
          await audioContext.resume();
          console.log('AudioContext å·²æ¢å¤:', audioContext.state);
        }
        console.log('AudioContext çŠ¶æ€:', audioContext.state);
        console.log('AudioContext é‡‡æ ·ç‡:', audioContext.sampleRate);
      } catch (resumeErr) {
        console.warn('AudioContext æ¢å¤å¤±è´¥ï¼ˆå¯èƒ½éœ€è¦ç”¨æˆ·æ‰‹åŠ¿ï¼‰:', resumeErr);
      }

      // å¯ç”¨éŸ³è½¨
      try {
        stream.getAudioTracks().forEach(track => {
          console.log('éŸ³è½¨çŠ¶æ€:', {
            enabled: track.enabled,
            muted: track.muted,
            readyState: track.readyState,
            label: track.label
          });
          if (!track.enabled) track.enabled = true;
        });
      } catch (e) {
        console.warn('æ— æ³•è®¾ç½®éŸ³è½¨å¯ç”¨çŠ¶æ€:', e);
      }

      // ä¿å­˜å¼•ç”¨
      audioContextRef.current = audioContext;
      analyserRef.current = analyser;
      dataArrayRef.current = new Uint8Array(analyser.frequencyBinCount);
      streamRef.current = stream!;

      console.log('å¼€å§‹éŸ³é¢‘åˆ†æ...');

      // åˆå§‹åŒ–LLMå¼¹å¹•ç®¡çº¿
      try {
        console.log('åˆå§‹åŒ–LLMå¼¹å¹•ç®¡çº¿...');
        if (danmuEnabled) {
          // å¦‚æœå¼¹å¹•å¯ç”¨ï¼Œç›´æ¥å¯åŠ¨ï¼Œè®©ç®¡çº¿å†…éƒ¨å¤„ç†åˆå§‹åŒ–
          danmuPipelineRef.current.start();
          console.log('LLMå¼¹å¹•ç®¡çº¿å¯åŠ¨å‘½ä»¤å·²å‘é€');
        } else {
          console.log('LLMå¼¹å¹•ç®¡çº¿å·²å‡†å¤‡ï¼ˆç­‰å¾…å¯åŠ¨ï¼‰');
        }
      } catch (e) {
        console.warn('LLMå¼¹å¹•ç®¡çº¿åˆå§‹åŒ–å¤±è´¥:', e);
      }

      // åˆå§‹åŒ– YAMNet æ¨¡å‹ï¼ˆä»…åœ¨æ˜¾å¼å¼€å¯å†…è”åŠ è½½æ—¶ï¼‰
      try {
        const env = (process as any)?.env || (window as any)?.process?.env || {};
        const inlineYamnet = String(env.NEXT_PUBLIC_INLINE_YAMNET ?? 'false') === 'true';
        if (inlineYamnet) {
          if (!yamnetModelRef.current) {
            console.log('åŠ è½½ YAMNet æ¨¡å‹...');
            yamnetModelRef.current = await loadYAMNetModel();
            if (yamnetModelRef.current) {
              console.log('YAMNet æ¨¡å‹åŠ è½½æˆåŠŸ');
              // åˆå§‹åŒ–éŸ³é¢‘ç¼“å†²åŒº
              yamnetBufferRef.current = new Float32Array(15600); // YAMNet éœ€è¦çš„ç¼“å†²åŒºå¤§å°
            }
          }
        } else {
          console.log('è·³è¿‡å†…è” YAMNet åŠ è½½ï¼ˆç”± Worker è´Ÿè´£åˆ†ç±»ï¼Œæˆ–æœªå¯ç”¨ï¼‰ã€‚');
        }
      } catch (e) {
        console.warn('YAMNet æ¨¡å‹åŠ è½½å¤±è´¥:', e);
      }

      // åˆå§‹åŒ– Meyda ç‰¹å¾æå–
      try {
        // ç¯å¢ƒå¼€å…³ï¼šç¦ç”¨æ–°é¢‘è°±ç®¡çº¿æ—¶ï¼Œè·³è¿‡ Meyda/Mel é¢‘è°±ï¼ˆå›é€€è€æ–¹æ¡ˆï¼‰
        const spectrumEnabled = (() => {
          try {
            const env = (process as any)?.env || (window as any)?.process?.env || {};
            const e = env.NEXT_PUBLIC_SPECTRUM_ENABLED;
            const f = env.NEXT_PUBLIC_SPECTRUM_FALLBACK;
            if (String(f ?? 'false') === 'true') return false;
            return String(e ?? 'true') !== 'false';
          } catch (_) { return true; }
        })();

        console.log('ğŸµ æ£€æŸ¥ Meyda åˆå§‹åŒ–æ¡ä»¶:', {
          spectrumEnabled,
          hasMeyda: !!Meyda,
          isBrowser: (Meyda as any)?.isBrowser,
          meydaVersion: (Meyda as any)?.version
        });

        console.log('ğŸµ æ£€æŸ¥ Meyda åˆå§‹åŒ–æ¡ä»¶:', {
          spectrumEnabled,
          hasMeyda: !!Meyda,
          isBrowser: (Meyda as any)?.isBrowser,
          meydaVersion: (Meyda as any)?.version
        });

        if (spectrumEnabled && Meyda && typeof window !== 'undefined') {
          console.log('ğŸµ åˆå§‹åŒ– Meyda ç‰¹å¾æå–...');
          console.log('ğŸµ Meyda ç‰ˆæœ¬:', (Meyda as any).version);
          console.log('ğŸµ æ”¯æŒçš„ç‰¹å¾:', Object.keys(Meyda.featureExtractors));
          meydaAnalyzerRef.current = Meyda.createMeydaAnalyzer({
            audioContext,
            source,
            bufferSize: 1024,
            featureExtractors: [
              'rms',
              'spectralCentroid',
              'zcr',
              'mfcc',
              'spectralFlatness',
              'chroma',
              'spectralRolloff',
              'spectralSpread',
              'spectralSkewness',
              'spectralKurtosis',
              'loudness',
              'perceptualSpread',
              'perceptualSharpness',
            ],
            callback: (f: any) => {
              console.log('ğŸµ Meyda å›è°ƒè¢«è°ƒç”¨:', f);
              try {
                // å¥å£®æ€§æ£€æŸ¥ï¼šç¡®ä¿ Meyda è¿”å›äº†æœ‰æ•ˆæ•°æ®
                if (!f || typeof f !== 'object') {
                  console.warn('ğŸµ Meyda å›è°ƒ: æ— æ•ˆçš„ç‰¹å¾æ•°æ®', f);
                  return;
                }
                
                // å¤„ç† Meyda ç‰¹å¾æ•°æ®
                const processedFeatures = {
                  rms: typeof f.rms === 'number' ? f.rms : 0,
                  spectralCentroid: typeof f.spectralCentroid === 'number' ? f.spectralCentroid : 0,
                  zcr: typeof f.zcr === 'number' ? f.zcr : 0,
                  mfcc: Array.isArray(f.mfcc) ? f.mfcc : [],
                  spectralFlatness: typeof f.spectralFlatness === 'number' ? f.spectralFlatness : 0,
                  chroma: Array.isArray(f.chroma) ? f.chroma : [],
                  // Mock spectralContrast å®ç°
                  spectralContrast: Array.isArray(f.chroma) ? f.chroma.slice(0, 12).map((c: number) => Math.max(0, Math.min(1, c))) : new Array(12).fill(0),
                  // Mock spectralBandwidth å®ç°
                  spectralBandwidth: typeof f.spectralSpread === 'number' ? Math.max(0, Math.min(1, f.spectralSpread / 1000)) : 0,
                  spectralRolloff: typeof f.spectralRolloff === 'number' ? f.spectralRolloff : 0,
                  spectralSpread: typeof f.spectralSpread === 'number' ? f.spectralSpread : 0,
                  spectralSkewness: typeof f.spectralSkewness === 'number' ? f.spectralSkewness : 0,
                  spectralKurtosis: typeof f.spectralKurtosis === 'number' ? f.spectralKurtosis : 0,
                  loudness: typeof f.loudness === 'number' ? f.loudness : 0,
                  perceptualSpread: typeof f.perceptualSpread === 'number' ? f.perceptualSpread : 0,
                  perceptualSharpness: typeof f.perceptualSharpness === 'number' ? f.perceptualSharpness : 0,
                  // è®¡ç®—æ´¾ç”Ÿç‰¹å¾
                  voiceProb: calculateVoiceProbability(f),
                  percussiveRatio: calculatePercussiveRatio(f),
                  harmonicRatio: calculateHarmonicRatio(f)
                } as any;

                // é¢‘è°±ä¸‰æ®µèƒ½é‡ï¼ˆä½/ä¸­/é«˜ï¼‰ç”¨äºé¢‘è°±ä¼˜å…ˆæ˜ å°„
                try {
                  const analyser = analyserRef.current;
                  const audioCtx = audioContextRef.current;
                  if (analyser && audioCtx) {
                    // FPS ç»Ÿè®¡
                    try {
                      fpsStateRef.current.frames += 1;
                      const now = (typeof performance !== 'undefined' ? performance.now() : Date.now());
                      if (now - fpsStateRef.current.lastTs >= 1000) {
                        fpsStateRef.current.fps = fpsStateRef.current.frames * 1000 / Math.max(1, now - fpsStateRef.current.lastTs);
                        fpsStateRef.current.frames = 0;
                        fpsStateRef.current.lastTs = now;
                        // è‡ªé€‚åº”é™æ¡£ï¼ˆç§»åŠ¨ç«¯ï¼‰ï¼Œä½äº45fpsé™åˆ—æ•°ä¸æ›´æ–°é¢‘ç‡
                        const isMobileUA = /Mobile|Android|iPhone|iPad|iPod/i.test(navigator.userAgent || '');
                        if (isMobileUA && fpsStateRef.current.fps < 45) {
                          melDesiredColsRef.current = 32;
                          spectrumUpdateDividerRef.current = 2; // æ¯2å¸§æ›´æ–°ä¸€æ¬¡é¢‘è°±
                          // å¼ºåˆ¶ä¸‹æ¬¡é‡å»ºæ˜ å°„
                          melConfigRef.current = null;
                        } else if (isMobileUA && fpsStateRef.current.fps >= 55) {
                          melDesiredColsRef.current = 48;
                          spectrumUpdateDividerRef.current = 1;
                          melConfigRef.current = null;
                        }
                      }
                    } catch (_) {}

                    // è·³å¸§æ›´æ–°ï¼šé™ä½é¢‘è°±è®¡ç®—é¢‘ç‡ä»¥ä¿å¸§
                    if (spectrumUpdateDividerRef.current > 1) {
                      const skip = Math.floor((Math.random() * spectrumUpdateDividerRef.current));
                      if (skip > 0) {
                        // ä»ç„¶å›å¡«ä¸Šä¸€æ¬¡ slow å€¼ï¼Œç»´æŒå¯ç”¨
                        (processedFeatures as any).bandLow = spectrumStateRef.current.lowSlow;
                        (processedFeatures as any).bandMid = spectrumStateRef.current.midSlow;
                        (processedFeatures as any).bandHigh = spectrumStateRef.current.highSlow;
                        (processedFeatures as any).bandColumns = Array.from(spectrumStateRef.current.columnsSlow || []);
                        throw 'skip_update';
                      }
                    }

                    const binCount = analyser.frequencyBinCount;
                    const floatData = new Float32Array(binCount);
                    analyser.getFloatFrequencyData(floatData); // dB, [-140, 0]

                    const sampleRate = audioCtx.sampleRate;
                    const fftSize = analyser.fftSize;
                    const binHz = sampleRate / fftSize;

                    // åˆå§‹åŒ– MEL æ–­ç‚¹æ˜ å°„ï¼ˆç§»åŠ¨ç«¯åˆ—æ•°å‡å°‘ï¼‰
                    if (!melConfigRef.current) {
                      const isMobileUA = /Mobile|Android|iPhone|iPad|iPod/i.test(navigator.userAgent || '');
                      const desired = melDesiredColsRef.current ?? (isMobileUA ? 48 : 64);
                      const MEL_COLS = Math.max(16, Math.min(128, desired));
                      const minHz = 20, maxHz = 8000;
                      // ç®€åŒ–çš„ç­‰æ¯”åˆ»åº¦è¿‘ä¼¼ MELï¼ˆé¿å…å¼•å…¥é¢å¤–å‡½æ•°ï¼‰ï¼šåœ¨ 20-8000Hz ä¸Šå¯¹æ•°åˆ†å¸ƒ
                      const toHz = (t: number) => minHz * Math.pow(maxHz / minHz, t);
                      const breakpointsHz: number[] = [];
                      for (let i = 0; i <= MEL_COLS; i++) breakpointsHz.push(toHz(i / MEL_COLS));
                      const binMap: number[] = breakpointsHz.map(hz => Math.max(0, Math.min(binCount - 1, Math.round(hz / binHz))));
                      melConfigRef.current = { binMap, cols: MEL_COLS, minHz, maxHz };
                    }

                    const { binMap, cols: MEL_COLS } = melConfigRef.current!;
                    const columns = new Float32Array(MEL_COLS);
                    // dBâ†’å¹…åº¦å½’ä¸€åŒ–ï¼ˆ0..1ï¼‰
                    const amp = (db: number) => {
                      const clamped = Math.max(-140, Math.min(0, db || -140));
                      return Math.pow(10, (clamped + 140) / 20);
                    };
                    for (let c = 0; c < MEL_COLS; c++) {
                      const start = binMap[c];
                      const end = binMap[c + 1];
                      if (end <= start) { columns[c] = 0; continue; }
                      let sum = 0;
                      for (let k = start; k < end; k++) sum += amp(floatData[k]);
                      columns[c] = sum / Math.max(1, end - start);
                    }

                    // ä¸‰æ®µèƒ½é‡ï¼šæŒ‰åˆ—èŒƒå›´èšåˆ
                    const idxLowEnd = Math.floor(MEL_COLS * 0.22);
                    const idxMidEnd = Math.floor(MEL_COLS * 0.65);
                    const avgRange = (s: number, e: number) => {
                      let sum = 0; for (let i = s; i < e; i++) sum += columns[i];
                      return e > s ? sum / (e - s) : 0;
                    };
                    const lowInst = avgRange(0, idxLowEnd);
                    const midInst = avgRange(idxLowEnd, idxMidEnd);
                    const highInst = avgRange(idxMidEnd, MEL_COLS);

                    // åŒæ—¶é—´å¸¸æ•°ï¼ˆbi-smoothï¼‰
                    const bi = (cur: number, next: number, attack: number, release: number) => cur + (next > cur ? attack : release) * (next - cur);
                    const S = spectrumStateRef.current;
                    const levelInst = Math.max(0, Math.min(1, (processedFeatures as any).rms || 0));
                    // æ¨èå‚æ•°ï¼ˆå¯åç»­æå‡ä¸ºå¯é…ï¼‰
                    S.levelSlow = bi(S.levelSlow, levelInst, 0.45, 0.12);
                    S.lowSlow = bi(S.lowSlow, lowInst, 0.25, 0.08);
                    S.midSlow = bi(S.midSlow, midInst, 0.35, 0.10);
                    S.highSlow = bi(S.highSlow, highInst, 0.60, 0.18);

                    // åˆ—ç¼“å†²ï¼ˆinstantâ†’columnsSmoothï¼‰
                    if (!S.columnsSlow || S.columnsSlow.length !== MEL_COLS) {
                      S.columnsSlow = new Float32Array(MEL_COLS);
                      S.columnsSlow.set(columns);
                      } else {
                      for (let i = 0; i < MEL_COLS; i++) {
                        const next = columns[i];
                        const prev = S.columnsSlow[i];
                        // é«˜åˆ—ç”¨æ›´å¹³æ»‘çš„é‡Šæ”¾ï¼Œå‡å°‘é—ªçƒ
                        const a = 0.5; const r = 0.2;
                        S.columnsSlow[i] = bi(prev, next, a, r);
                      }
                    }

                    // å†™å› processedFeaturesï¼šä½¿ç”¨ slow å€¼å¢å¼ºç¨³å®šæ€§
                    (processedFeatures as any).bandLow = Math.max(0, Math.min(1, S.lowSlow));
                    (processedFeatures as any).bandMid = Math.max(0, Math.min(1, S.midSlow));
                    (processedFeatures as any).bandHigh = Math.max(0, Math.min(1, S.highSlow));
                    (processedFeatures as any).bandColumns = Array.from(S.columnsSlow);
                    bandColumnsRef.current = Array.from(S.columnsSlow);

                    // å†å²å¸§ï¼ˆç®€è¦ï¼‰
                    try {
                      const frame = {
                        level: { instant: levelInst, slow: S.levelSlow },
                        bands: {
                          low: { instant: lowInst, slow: S.lowSlow },
                          mid: { instant: midInst, slow: S.midSlow },
                          high: { instant: highInst, slow: S.highSlow },
                        },
                        columns,
                        columnsSmooth: new Float32Array(S.columnsSlow),
                      };
                      spectrumHistoryRef.current.push(frame);
                      if (spectrumHistoryRef.current.length > 32) spectrumHistoryRef.current.shift();
                    } catch (_) {}
                  }
                } catch (bandErr) {
                  if (bandErr === 'skip_update') { /* é™é¢‘è·³è¿‡ */ } else {
                  console.warn('è®¡ç®—é¢‘æ®µèƒ½é‡å¤±è´¥:', bandErr);
                  }
                }

                // è½»é‡ BPM ä¼°è®¡ï¼šä½¿ç”¨ spectralFlux å³°å€¼çš„é—´éš”ï¼ˆæ»‘çª—ä¸­ä½æ•°ï¼‰
                try {
                  const flux = 0; // spectralFlux å·²ç§»é™¤ï¼Œä½¿ç”¨é»˜è®¤å€¼
                  const audioCtx = audioContextRef.current;
                  if (audioCtx) {
                    const nowSec = audioCtx.currentTime;
                    const state = bpmStateRef.current;
                    // åŠ¨æ€é˜ˆå€¼ï¼ˆä¸è¿‘æœŸ RMS/èƒ½é‡æ— å…³çš„ç®€å•çº¿æ€§ï¼‰ï¼š
                    const fluxThresh = 0.12; // ç»éªŒé˜ˆå€¼ï¼Œç§»åŠ¨ç«¯ç¨³å®š
                    const minIoISec = 0.18;   // æœ€çŸ­ 180ms ~ 333 BPM ä¸Šé™
                    if (flux > fluxThresh && (nowSec - state.lastOnsetSec) > minIoISec) {
                      if (state.lastOnsetSec > 0) {
                        const interval = nowSec - state.lastOnsetSec;
                        // åˆç†åŒºé—´è¿‡æ»¤ï¼ˆ60â€“180 BPMï¼‰
                        if (interval >= 0.333 && interval <= 1.0) {
                          state.intervals.push(interval);
                          if (state.intervals.length > 16) state.intervals.shift();
                          // å–ä¸­ä½æ•°æŠ—å™ª
                          const sorted = [...state.intervals].sort((a,b)=>a-b);
                          const mid = sorted.length ? sorted[Math.floor(sorted.length/2)] : interval;
                          const bpm = 60 / Math.max(1e-6, mid);
                          // ç®€å•ç½®ä¿¡åº¦ï¼šæ ·æœ¬æ•°ä¸æ–¹å·®çš„å‡½æ•°
                          const mean = sorted.reduce((s,v)=>s+v,0) / Math.max(1, sorted.length);
                          const variance = sorted.reduce((s,v)=>s+(v-mean)*(v-mean),0) / Math.max(1, sorted.length);
                          const conf = Math.max(0, Math.min(1, (sorted.length/16) * (1.0 - Math.min(1, variance/0.1))));
                          state.bpm = bpm;
                          state.confidence = conf;
                        }
                      }
                      state.lastOnsetSec = nowSec;
                    }

                    // å‘å¸ƒæ¡ä»¶ï¼šç½®ä¿¡åº¦è¶³å¤Ÿä¸” BPM åœ¨ 60â€“180 èŒƒå›´
                    if (state.bpm > 0 && state.confidence >= 0.45 && state.bpm >= 60 && state.bpm <= 180) {
                      // ç›¸ä½åŒæ­¥ï¼šåŸºäº AudioContext æ—¶é—´ç´¯ç§¯
                      const tp = tempoPhaseRef.current;
                      const dt = Math.max(0, nowSec - (tp.lastTime || nowSec));
                      tp.phase = (tp.phase + (state.bpm / 60) * dt) % 1;
                      tp.lastTime = nowSec;
                      (processedFeatures as any).tempo = { bpm: Math.round(state.bpm), confidence: state.confidence, phase: tp.phase } as any;
                    }
                  }
                } catch (bpmErr) {
                  console.warn('BPM ä¼°è®¡å¤±è´¥:', bpmErr);
                }

                // è½»é‡éŸ³é«˜æ£€æµ‹ï¼ˆæ¡ä»¶è§¦å‘ï¼šè°æ³¢/äººå£°å ä¼˜ + å¸§ç‡è¶³å¤Ÿï¼›æ¯4å¸§è®¡ç®—ä¸€æ¬¡ï¼‰
                try {
                  const audioCtx = audioContextRef.current;
                  const isHarmonic = (((processedFeatures as any).harmonicRatio ?? 0) > 0.55) || (((processedFeatures as any).voiceProb ?? 0) > 0.55);
                  const fpsOk = (fpsStateRef.current?.fps ?? 60) >= 45;
                  const ps = pitchStateRef.current;
                  ps.frame = (ps.frame + 1) % 4;
                  if (audioCtx && isHarmonic && fpsOk && ps.frame === 0 && analyserRef.current) {
                    const N = analyserRef.current.fftSize;
                    const td = new Float32Array(N);
                    analyserRef.current.getFloatTimeDomainData(td);
                    // ç®€åŒ–ç‰ˆ YIN-ishï¼šé‡‡ç”¨è‡ªç›¸å…³è¿‘ä¼¼ï¼ˆåªæ±‚ä¸»å³°ï¼‰ï¼Œä½è®¡ç®—é‡
                    const maxLag = Math.min(N >> 1, Math.floor(audioCtx.sampleRate / 80)); // æœ€ä½80Hz
                    const minLag = Math.max(2, Math.floor(audioCtx.sampleRate / 1000)); // æœ€é«˜1000Hz
                    let bestLag = 0; let bestVal = 0;
                    for (let lag = minLag; lag <= maxLag; lag++) {
                      let sum = 0; let cnt = 0;
                      for (let i = 0; i + lag < N; i += 2) { // æ­¥é•¿2 é™æˆæœ¬
                        sum += td[i] * td[i + lag];
                        cnt++;
                      }
                      const val = cnt ? sum / cnt : 0;
                      if (val > bestVal) { bestVal = val; bestLag = lag; }
                    }
                    const hz = bestLag > 0 ? audioCtx.sampleRate / bestLag : 0;
                    const conf = Math.max(0, Math.min(1, (bestVal + 1) / 2));
                    // å¹³æ»‘è¾“å‡º
                    ps.smoothHz = ps.smoothHz ? (ps.smoothHz * 0.7 + hz * 0.3) : hz;
                    ps.lastHz = hz; ps.confidence = conf;
                    (processedFeatures as any).pitchHz = ps.smoothHz;
                    (processedFeatures as any).pitchConf = conf;
                    // è¿‘ä¼¼éŸ³åï¼ˆA4=440Hzï¼Œ12-TETï¼‰
                    const noteNum = 69 + 12 * Math.log2(Math.max(1e-6, ps.smoothHz / 440));
                    const noteIndex = Math.round(noteNum);
                    const names = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B'];
                    const name = names[(noteIndex + 1200) % 12];
                    const octave = Math.floor(noteIndex / 12) - 1;
                    (processedFeatures as any).pitchName = `${name}${octave}`;
                  }
                } catch (pitchErr) {
                  // å¿½ç•¥éŸ³é«˜é”™è¯¯ï¼Œä¿æŒä¸»æµç¨‹
                }

                // èµ·éŸ³/éŸ³ç¬¦è¾¹ç•Œï¼šåœ¨ spectralFlux å³°å€¼åŸºç¡€ä¸ŠåŠ å…¥æ»åä¸æœ€çŸ­é—´éš”
                try {
                  const audioCtx = audioContextRef.current;
                  if (audioCtx) {
                    const nowSec = audioCtx.currentTime;
                    const os = onsetStateRef.current;
                    const flux = 0; // spectralFlux å·²ç§»é™¤ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    const rmsNow = (processedFeatures as any).rms ?? 0;
                    const minGap = 0.12; // 120ms æœ€çŸ­é—´éš”
                    const fluxGate = 0.12; // ç»éªŒé—¨é™
                    const rmsGate = 0.02; // ä½èƒ½é‡æŠ‘åˆ¶
                    if (flux > fluxGate && rmsNow > rmsGate && (nowSec - os.lastOnsetSec) > minGap && os.armed) {
                      (processedFeatures as any).noteOn = true;
                      os.lastOnsetSec = nowSec;
                      os.armed = false;
                    } else {
                      (processedFeatures as any).noteOn = false;
                      // æ»åé‡Šæ”¾ï¼šåœ¨ 80ms åé‡æ–°æ­¦è£…
                      if (!os.armed && (nowSec - os.lastOnsetSec) > 0.08) os.armed = true;
                    }
                  }
                } catch (onsetErr) {
                  // å¿½ç•¥
                }
                
                setFeatures(processedFeatures);
                
                // å°†éŸ³é¢‘ç‰¹å¾ä¼ é€’ç»™LLMå¼¹å¹•ç®¡çº¿ - ä½¿ç”¨ ref è·å–æœ€æ–°çŠ¶æ€
                if (danmuPipelineRef.current.isActive && processedFeatures) {
                  try {
                    // å¥å£®æ€§æ£€æŸ¥ï¼šç¡®ä¿ RMS å€¼æœ‰æ•ˆ
                    const rmsValue = processedFeatures.rms;
                    if (typeof rmsValue !== 'number' || isNaN(rmsValue) || !isFinite(rmsValue)) {
                      console.warn('ğŸµ å¼¹å¹•ç®¡çº¿: RMS å€¼æ— æ•ˆï¼Œè·³è¿‡å¼¹å¹•ç”Ÿæˆ', rmsValue);
                      return;
                    }
                    
                    // æ„å»ºå®Œæ•´çš„ç‰¹å¾å¯¹è±¡ä¾›LLMåˆ†æ
                    const fullFeatures = {
                      ...processedFeatures,
                      yamnetResults,
                      timestamp: Date.now(),
                      preset: currentPreset,
                      sensitivity: sensitivity
                    };
                    
                    // ä¼ é€’ç»™LLMå¼¹å¹•ç®¡çº¿ - ä½¿ç”¨ ref è·å–æœ€æ–°çŠ¶æ€
                    danmuPipelineRef.current.handleAudioFeatures(rmsValue, fullFeatures);
                      
                      // è°ƒè¯•æ—¥å¿—
          if (Math.random() < 0.1) {
                      console.log('ğŸµ LLMå¼¹å¹•ç®¡çº¿å¤„ç†ç‰¹å¾:', {
                        rms: processedFeatures.rms,
                        style: danmuPipelineRef.current.currentStyle,
                        danmuCount: danmuPipelineRef.current.danmuCount,
                        dominantInstrument: danmuPipelineRef.current.dominantInstrument
                      });
                    }
                  } catch (e) {
                    console.warn('LLMå¼¹å¹•ç®¡çº¿å¤„ç†é”™è¯¯:', e);
                  }
                }
                
                // YAMNet åˆ†ç±»ï¼ˆæ¯30å¸§æ‰§è¡Œä¸€æ¬¡ï¼Œå‡å°‘è®¡ç®—è´Ÿè½½ï¼‰
                if (yamnetModelRef.current && yamnetBufferRef.current && Math.random() < 0.033) {
                  try {
                    // è·å–å½“å‰éŸ³é¢‘ç¼“å†²åŒº
                    const currentBuffer = new Float32Array(analyser.fftSize);
                    analyser.getFloatTimeDomainData(currentBuffer);
                    
                    // æ›´æ–° YAMNet ç¼“å†²åŒºï¼ˆæ»‘åŠ¨çª—å£ï¼‰
                    const bufferSize = yamnetBufferRef.current.length;
                    const newDataSize = Math.min(currentBuffer.length, bufferSize);
                    
                    // ç§»åŠ¨æ—§æ•°æ®
                    yamnetBufferRef.current.copyWithin(0, newDataSize);
                    // æ·»åŠ æ–°æ•°æ®
                    yamnetBufferRef.current.set(currentBuffer.slice(0, newDataSize), bufferSize - newDataSize);
                    
                    // æ‰§è¡Œ YAMNet åˆ†ç±»
                    const yamnetResults = classifyWithYAMNet(yamnetModelRef.current, yamnetBufferRef.current);
                    if (yamnetResults) {
                      setYamnetResults(yamnetResults);
                      
                      // è°ƒè¯•æ—¥å¿—
                      if (Math.random() < 0.1) {
                        console.log('YAMNet åˆ†ç±»ç»“æœ:', {
                          topClass: yamnetResults.topClasses[0]?.label,
                          confidence: yamnetResults.topClasses[0]?.confidence?.toFixed(3),
                          instruments: yamnetResults.instruments.slice(0, 3),
                          events: yamnetResults.events.slice(0, 3)
                        });
                      }
                    }
                  } catch (e) {
                    console.warn('YAMNet åˆ†ç±»é”™è¯¯:', e);
                  }
                }
                
                // è°ƒè¯•æ—¥å¿— - æ¯100å¸§è¾“å‡ºä¸€æ¬¡
                if (Math.random() < 0.01) {
                  console.log('Meyda ç‰¹å¾:', {
                    rms: processedFeatures.rms.toFixed(3),
                    spectralCentroid: processedFeatures.spectralCentroid.toFixed(3),
                    zcr: processedFeatures.zcr.toFixed(3),
                    mfccLength: processedFeatures.mfcc.length,
                    chromaLength: processedFeatures.chroma.length
                  });
                }
              } catch (e) {
                console.warn('Meyda ç‰¹å¾å¤„ç†é”™è¯¯:', e);
              }
            },
          });
          meydaAnalyzerRef.current.start();
          console.log('Meyda ç‰¹å¾æå–å·²å¯åŠ¨');
        } else {
          console.log('ğŸµ è·³è¿‡ Meyda ç‰¹å¾æå–:', {
            reason: !spectrumEnabled ? 'spectrumEnabled=false' : 
                   !Meyda ? 'MeydaæœªåŠ è½½' : 
                   (!(Meyda as any).isBrowser && typeof window === 'undefined') ? 'éæµè§ˆå™¨ç¯å¢ƒ' : 'Meyda.isBrowseræ£€æŸ¥å¤±è´¥'
          });
        }
      } catch (e) {
        console.warn('Meyda åˆå§‹åŒ–å¤±è´¥:', e);
      }

      // å…ˆæ ‡è®°ä¸ºè¿è¡Œï¼Œå†å¯åŠ¨å¾ªç¯
      setIsRunning(true);
      
      // å»¶è¿Ÿå¯åŠ¨åˆ†æå¾ªç¯ï¼Œç¡®ä¿çŠ¶æ€å·²æ›´æ–°
      setTimeout(() => {
        console.log('å¯åŠ¨éŸ³é¢‘åˆ†æå¾ªç¯...');
        console.log('isRunningçŠ¶æ€:', isRunning);
        console.log('analyserRef.current:', !!analyserRef.current);
        
        // æµ‹è¯•éŸ³é¢‘æ•°æ®è·å–
        const testAnalyser = analyserRef.current;
        if (testAnalyser) {
          const testBuffer = new Float32Array(testAnalyser.fftSize);
          testAnalyser.getFloatTimeDomainData(testBuffer);
          console.log('æµ‹è¯•éŸ³é¢‘æ•°æ®å‰10ä¸ªå€¼:', Array.from(testBuffer.slice(0, 10)));
        }
        
        analyzeAudio();
      }, 100);
      
      console.log('éŸ³é¢‘å¤„ç†å·²å¯åŠ¨');
    } catch (error) {
      console.error('å¯åŠ¨éŸ³é¢‘å¤„ç†å¤±è´¥:', error);
      try { setDebugInfo(prev => ({ ...prev, lastError: String(error) })); } catch (_) {}
    }
  }, [analyzeAudio]);

  // åœæ­¢éŸ³é¢‘å¤„ç† - å‚è€ƒä¸»é¡µé¢çš„å®ç°
  const stopAudioProcessing = useCallback(() => {
    // åœæ­¢éŸ³é¢‘åˆ†æå¾ªç¯
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }

    // åœæ­¢ Meyda åˆ†æå™¨
    if (meydaAnalyzerRef.current) {
      try {
        meydaAnalyzerRef.current.stop();
        meydaAnalyzerRef.current = null;
        console.log('Meyda åˆ†æå™¨å·²åœæ­¢');
      } catch (e) {
        console.warn('åœæ­¢ Meyda åˆ†æå™¨æ—¶å‡ºé”™:', e);
      }
    }

    // æ¸…ç† YAMNet æ¨¡å‹
    if (yamnetModelRef.current) {
      try {
        yamnetModelRef.current.dispose();
        yamnetModelRef.current = null;
        yamnetBufferRef.current = null;
        console.log('YAMNet æ¨¡å‹å·²æ¸…ç†');
      } catch (e) {
        console.warn('æ¸…ç† YAMNet æ¨¡å‹æ—¶å‡ºé”™:', e);
      }
    }

    // æ¸…ç†LLMå¼¹å¹•ç®¡çº¿
    try {
      if (danmuPipeline.isActive || danmuPipeline.isReady) {
        danmuPipeline.stop();
        console.log('LLMå¼¹å¹•ç®¡çº¿å·²åœæ­¢');
      }
      } catch (e) {
      console.warn('æ¸…ç†LLMå¼¹å¹•ç®¡çº¿æ—¶å‡ºé”™:', e);
    }

    // æ–­å¼€éŸ³é¢‘è¿æ¥
    if (audioContextRef.current) {
      try {
        // å…ˆæ–­å¼€æ‰€æœ‰éŸ³é¢‘èŠ‚ç‚¹
        if (audioContextRef.current.state !== 'closed') {
          audioContextRef.current.close().then(() => {
            console.log('AudioContext å·²å…³é—­');
          }).catch(err => {
            console.warn('å…³é—­ AudioContext æ—¶å‡ºé”™:', err);
          });
        }
      } catch (e) {
        console.warn('æ–­å¼€éŸ³é¢‘è¿æ¥æ—¶å‡ºé”™:', e);
      }
      audioContextRef.current = null;
    }

    // åœæ­¢åª’ä½“æµ
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => {
        console.log('åœæ­¢éŸ³è½¨:', track.kind, track.label, track.readyState);
        track.stop();
        console.log('éŸ³è½¨å·²åœæ­¢:', track.kind, track.label);
      });
      streamRef.current = null;
      console.log('åª’ä½“æµå·²åœæ­¢');
    }

    // æ¸…ç†æ‰€æœ‰éŸ³é¢‘èŠ‚ç‚¹
    if (sourceRef.current) {
      try {
        sourceRef.current.disconnect();
        sourceRef.current = null;
        console.log('éŸ³é¢‘æºèŠ‚ç‚¹å·²æ–­å¼€');
      } catch (e) {
        console.warn('æ–­å¼€éŸ³é¢‘æºèŠ‚ç‚¹æ—¶å‡ºé”™:', e);
      }
    }

    if (gainRef.current) {
      try {
        gainRef.current.disconnect();
        gainRef.current = null;
        console.log('å¢ç›ŠèŠ‚ç‚¹å·²æ–­å¼€');
      } catch (e) {
        console.warn('æ–­å¼€å¢ç›ŠèŠ‚ç‚¹æ—¶å‡ºé”™:', e);
      }
    }

    analyserRef.current = null;
    dataArrayRef.current = null;
    setIsRunning(false);
    setAudioLevel(0);
    setFeatures(null);
    setYamnetResults(null);

    // å¼ºåˆ¶é‡ç½®æ‰€æœ‰é¢‘è°±ç›¸å…³çŠ¶æ€
    bandColumnsRef.current = null;
    spectrumHistoryRef.current = [];
    spectrumStateRef.current = { levelSlow: 0, lowSlow: 0, midSlow: 0, highSlow: 0 };
    fpsStateRef.current = { lastTs: (typeof performance !== 'undefined' ? performance.now() : Date.now()), frames: 0, fps: 60 };
    tempoPhaseRef.current = { phase: 0, lastTime: 0 };
    pitchStateRef.current = { lastHz: 0, smoothHz: 0, confidence: 0, frame: 0 };
    onsetStateRef.current = { armed: true, lastOnsetSec: 0 };
    bpmStateRef.current = { lastOnsetSec: 0, intervals: [], bpm: 0, confidence: 0 };

    console.log('ğŸ›‘ éŸ³é¢‘å¤„ç†å·²å®Œå…¨åœæ­¢');
    console.log('ğŸ“Š çŠ¶æ€é‡ç½® - isRunning:', false, 'audioLevel:', 0, 'features:', null);
  }, []);

  // åˆ‡æ¢éº¦å…‹é£å¼€å…³
  const toggleMicrophone = useCallback((next?: boolean) => {
    try {
      const enable = typeof next === 'boolean' ? next : !microphoneEnabled;
      setMicrophoneEnabled(enable);

      if (enable) {
        // å¦‚æœå¯ç”¨éº¦å…‹é£ä¸”å½“å‰æ²¡æœ‰è¿è¡Œï¼Œåˆ™å¯åŠ¨éŸ³é¢‘å¤„ç†
        if (!isRunning) {
          startAudioProcessing();
        }
        console.log('ğŸ¤ éº¦å…‹é£å·²å¼€å¯');
      } else {
        // å¦‚æœç¦ç”¨éº¦å…‹é£ä¸”å½“å‰æ­£åœ¨è¿è¡Œï¼Œåˆ™åœæ­¢éŸ³é¢‘å¤„ç†
        if (isRunning) {
          stopAudioProcessing();
        }
        console.log('ğŸ¤ éº¦å…‹é£å·²å…³é—­');
      }
    } catch (err) {
      console.warn('åˆ‡æ¢éº¦å…‹é£å¤±è´¥:', err);
    }
  }, [microphoneEnabled, isRunning, startAudioProcessing, stopAudioProcessing]);

  // å¤„ç†é¢„è®¾é€‰æ‹©
  const handlePresetChange = useCallback((presetId: string) => {
    if (presetId === 'spectrum') {
      // é¢‘è°±ä¼˜å…ˆæ¨¡å¼åˆ‡æ¢
      setSpectrumPriority(!spectrumPriority);
      console.log('é¢‘è°±ä¼˜å…ˆæ¨¡å¼:', !spectrumPriority ? 'å¼€å¯' : 'å…³é—­');
      return;
    }

    // æ£€æŸ¥æ˜¯å¦ç‚¹å‡»çš„æ˜¯å½“å‰å·²é€‰ä¸­çš„é¢„è®¾
    if (presetId === currentPreset && isRunning) {
      // ç‚¹å‡»åŒä¸€é¢„è®¾ä¸”æ­£åœ¨è¿è¡Œ -> å…³é—­éº¦å…‹é£
      console.log('ğŸ”„ åœæ­¢éŸ³é¢‘å¤„ç† - ç‚¹å‡»åŒä¸€é¢„è®¾:', presetId);
      stopAudioProcessing();
      setMicrophoneEnabled(false);
      console.log('âœ… éº¦å…‹é£å·²å…³é—­');
    } else {
      // ç‚¹å‡»ä¸åŒé¢„è®¾æˆ–å½“å‰æœªè¿è¡Œ -> åˆ‡æ¢é¢„è®¾å¹¶å¼€å¯éº¦å…‹é£
      console.log('ğŸ”„ åˆ‡æ¢é¢„è®¾ - ä»', currentPreset, 'åˆ°', presetId);
      setCurrentPreset(presetId);
      setMicrophoneEnabled(true);
      if (!isRunning) {
        startAudioProcessing();
      }
      console.log('âœ… é¢„è®¾å·²åˆ‡æ¢è‡³:', presetId, 'éº¦å…‹é£å·²å¼€å¯');
    }
  }, [isRunning, startAudioProcessing, stopAudioProcessing, currentPreset, spectrumPriority]);

  
  // æ¸…ç†å‡½æ•°
  useEffect(() => {
    return () => {
      stopAudioProcessing();
    };
  }, [stopAudioProcessing]);

  // é”®ç›˜å¿«æ·é”®æ”¯æŒ
  useEffect(() => {
    const handleKeyDown = (e: KeyboardEvent) => {
      // æ•°å­—é”®åˆ‡æ¢é¢„è®¾
      const presetKeys = ['Digit1', 'Digit2', 'Digit3', 'Digit4'];
      const keyIndex = presetKeys.indexOf(e.code);
      if (keyIndex >= 0 && keyIndex < PRESET_OPTIONS.length) {
        e.preventDefault();
        handlePresetChange(PRESET_OPTIONS[keyIndex].id);
      }

      // éšè—çƒ­é”®ï¼šæŒ‰ä¸‹ D åˆ‡æ¢ Danmu å¼€å…³ï¼ŒæŒ‰ä¸‹ S åˆ‡æ¢é¢‘è°±ä¼˜å…ˆæ¨¡å¼
      if (e.code === 'KeyD') {
        e.preventDefault();
        toggleDanmu();
      }
      if (e.code === 'KeyS') {
        e.preventDefault();
        setSpectrumPriority(!spectrumPriority);
        console.log('é¢‘è°±ä¼˜å…ˆæ¨¡å¼:', !spectrumPriority ? 'å¼€å¯' : 'å…³é—­');
      }
    };

    if (typeof window !== 'undefined') {
      window.addEventListener('keydown', handleKeyDown);
      return () => window.removeEventListener('keydown', handleKeyDown);
    }
  }, [handlePresetChange, toggleDanmu, spectrumPriority]);

  // ç§»åŠ¨ç«¯/æµè§ˆå™¨è§£é”ï¼šåœ¨é¦–æ¬¡è§¦æ‘¸/ç‚¹å‡»æ—¶å°è¯• resume AudioContextï¼›è§£æ ?debug=1
  useEffect(() => {
    try {
      const url = new URL(window.location.href);
      if (url.searchParams.get('debug') === '1') setDebugVisible(true);
      // é‡‡é›†ä¸€æ¬¡æƒé™ä¸ç¯å¢ƒçŠ¶æ€
      (async () => {
        try {
          const micPerm = (navigator as any).permissions?.query
            ? await (navigator as any).permissions.query({ name: 'microphone' as any })
            : null;
          setDebugInfo(prev => ({
            ...prev,
            isSecure: !!(window as any).isSecureContext,
            hasMedia: !!navigator.mediaDevices,
            micPermission: micPerm?.state || 'unknown'
          }));
        } catch (_) {
          setDebugInfo(prev => ({
            ...prev,
            isSecure: !!(window as any).isSecureContext,
            hasMedia: !!navigator.mediaDevices
          }));
        }
      })();

      // æ£€æµ‹æ˜¯å¦åœ¨ iframe ä¸­ä»¥åŠæƒé™ç­–ç•¥ï¼ˆè‹¥å¯ç”¨ï¼‰
      try {
        const inIframe = window.top !== window.self;
        let policyMic: string | undefined;
        let policyCam: string | undefined;
        const anyDoc: any = document as any;
        const fp = anyDoc.permissionsPolicy || anyDoc.featurePolicy; // Chrome æœ‰ featurePolicyï¼Œæ–°çš„ä¸º permissionsPolicy
        if (fp && typeof fp.allowsFeature === 'function') {
          try { policyMic = fp.allowsFeature('microphone') ? 'allowed' : 'blocked'; } catch (_) {}
          try { policyCam = fp.allowsFeature('camera') ? 'allowed' : 'blocked'; } catch (_) {}
        }
        setEmbedInfo({ inIframe, policyMicrophone: policyMic, policyCamera: policyCam });
      } catch (_) {}
    } catch (_) {}

    const tryResume = async () => {
      try {
        const ctx = audioContextRef.current;
        if (ctx && ctx.state !== 'running') {
          await ctx.resume();
          console.log('åœ¨ç”¨æˆ·æ‰‹åŠ¿ä¸‹æ¢å¤ AudioContext:', ctx.state);
        }
        // é¦–æ¬¡ç”¨æˆ·æ‰‹åŠ¿ï¼šè‹¥æœªè¿è¡Œåˆ™å¯åŠ¨éŸ³é¢‘å¤„ç†
        if (!micStartedRef.current && !isRunning) {
          micStartedRef.current = true;
          try {
            await startAudioProcessing();
            console.log('é¦–æ¬¡ç”¨æˆ·æ‰‹åŠ¿è§¦å‘éº¦å…‹é£å¯åŠ¨');
          } catch (e) {
            console.warn('é¦–æ¬¡æ‰‹åŠ¿å¯åŠ¨éº¦å…‹é£å¤±è´¥:', e);
            micStartedRef.current = false; // å¤±è´¥åˆ™å…è®¸å†æ¬¡å°è¯•
          }
        }
      } catch (e) {
        console.warn('ç”¨æˆ·æ‰‹åŠ¿æ¢å¤ AudioContext å¤±è´¥:', e);
      }
    };
    const events = ['touchend', 'touchstart', 'click'];
    events.forEach(ev => window.addEventListener(ev, tryResume, { passive: true } as any));
    return () => events.forEach(ev => window.removeEventListener(ev, tryResume as any));
  }, []);

  return (
    <div className="min-h-screen bg-black text-white flex flex-col relative">
      {/* å…¨å±€æ ·å¼ - ç§»é™¤æ‰€æœ‰æŒ‰é’®çš„ç„¦ç‚¹æ ·å¼ */}
      <style jsx global>{`
        button:focus {
          outline: none !important;
          box-shadow: none !important;
          border: none !important;
        }
        button:focus-visible {
          outline: none !important;
          box-shadow: none !important;
          border: none !important;
        }
        button:active {
          outline: none !important;
          box-shadow: none !important;
          border: none !important;
        }
      `}</style>
      {/* å¯è§†åŒ–ç»„ä»¶ - å…¨å±èƒŒæ™¯ */}
      <div className="absolute inset-0 z-0">
        <Visualizer
          audioLevel={audioLevel}
          running={isRunning}
          preset={currentPreset as 'pulse' | 'accretion' | 'spiral' | 'mosaic' | 'wave'}
            features={features}
          sensitivity={sensitivity}
          spectrumPriority={spectrumPriority}
          audioWeights={{
            level: 1.0,
            bandLow: 1.2,
            bandMid: 1.0,
            bandHigh: 1.4,
            fluxPulse: 1.6,
            tempo: 1.0,
          }}
        />

        {/* å¼¹å¹•å®¹å™¨ */}
        <div id="danmu-container" className="absolute inset-0 pointer-events-none z-20"></div>
        
      </div>
      
      {/* è°ƒè¯•é¢æ¿ï¼ˆå³ä¸Šè§’ï¼‰ */}
      {debugVisible && (
        <div className="fixed top-2 right-2 z-30 bg-black/70 text-white/90 border border-white/10 rounded-md px-3 py-2 text-xs leading-relaxed max-w-[90vw]">
          <div className="flex items-center justify-between gap-2">
            <span className="font-bold">Mic Debug</span>
            <button
              onClick={() => setDebugVisible(false)}
              className="px-1 py-0.5 bg-white/10 hover:bg-white/20 rounded"
            >éšè—</button>
          </div>
          <div className="mt-1 grid grid-cols-2 gap-x-3 gap-y-1">
            <div>ctx: {debugInfo.ctxState}</div>
            <div>rate: {debugInfo.sampleRate}</div>
            <div>stream: {String(debugInfo.hasStream)}</div>
            <div>analyser: {String(debugInfo.hasAnalyser)}</div>
            <div>rms: {debugInfo.rms.toFixed(3)}</div>
            <div>maxAbs: {debugInfo.maxAbs.toFixed(3)}</div>
            <div>zero: {debugInfo.zeroCount}</div>
            <div>running: {String(isRunning)}</div>
            <div>secure: {String(debugInfo.isSecure)}</div>
            <div>media: {String(debugInfo.hasMedia)}</div>
            <div>perm: {debugInfo.micPermission}</div>
            <div>iframe: {String(embedInfo.inIframe)}</div>
            <div>danmu: {String(danmuEnabled)}</div>
            <div>pipeline: {String(danmuPipeline.isActive)}</div>
            <div>style: {danmuPipeline.currentStyle || 'none'}</div>
            <div>danmuCount: {danmuPipeline.danmuCount}</div>
            <div>instrument: {danmuPipeline.dominantInstrument || 'none'}</div>
            {embedInfo.policyMicrophone && (<div>pol-mic: {embedInfo.policyMicrophone}</div>)}
            {embedInfo.policyCamera && (<div>pol-cam: {embedInfo.policyCamera}</div>)}
          </div>
          <div className="mt-1">samples: {debugInfo.lastSamples.map(v => v.toFixed(2)).join(', ')}</div>
          {debugInfo.lastError && (
            <div className="mt-1 text-red-400 break-all">error: {debugInfo.lastError}</div>
          )}
          <div className="mt-2 flex gap-2">
            <button
              onClick={() => { try { startAudioProcessing(); } catch (_) {} }}
              className="px-2 py-1 bg-emerald-600 hover:bg-emerald-500 rounded"
            >å¯åŠ¨éº¦å…‹é£</button>
            <button
              onClick={() => { try { stopAudioProcessing(); } catch (_) {} }}
              className="px-2 py-1 bg-rose-600 hover:bg-rose-500 rounded"
            >åœæ­¢</button>
            <button
              onClick={() => {
                // å¯ç”¨Mosaicæµ‹è¯•æ¨¡å¼
                if (currentPreset === 'mosaic') {
                  console.log('ğŸµ å¯ç”¨Mosaicæµ‹è¯•æ¨¡å¼');
                  // è¿™é‡Œéœ€è¦è®¿é—®mosaicVisualå®ä¾‹ï¼Œæš‚æ—¶ç”¨æ—¥å¿—ä»£æ›¿
                  console.log('è¯·åœ¨æ§åˆ¶å°æ‰‹åŠ¨è°ƒç”¨: mosaicVisual.enableTestMode()');
                }
              }}
              className="px-2 py-1 bg-purple-600 hover:bg-purple-500 rounded"
            >æµ‹è¯•é¢‘è°±</button>
            <button
              onClick={async () => {
                try {
                  if (!audioContextRef.current) return;
                  await audioContextRef.current.resume();
                  setDebugInfo(prev => ({ ...prev, ctxState: audioContextRef.current?.state || 'unknown' }));
                } catch (e) {
                  console.warn('æ‰‹åŠ¨æ¢å¤å¤±è´¥:', e);
                }
              }}
              className="px-2 py-1 bg-sky-700 hover:bg-sky-600 rounded"
            >æ‰‹åŠ¨æ¢å¤</button>
          </div>
        </div>
      )}

      {/* é¢„è®¾é€‰æ‹©å™¨ - æ”¾åœ¨é¡¶éƒ¨ä½†ä¸è´´è¾¹ */}
      <div className="relative z-10 pt-16 portrait:pt-8 pb-8">
        <div className="flex gap-3 sm:gap-5 lg:gap-7 flex-nowrap justify-center items-center w-full px-2">
          {[...PRESET_OPTIONS, { id: 'danmu', label: 'Danmu', abbrMobile: 'DA' }].map((option, index) => {
            const graphemes = segmentGraphemes(option.label);
            const centerIndex = (graphemes.length - 1) / 2;
            const isSelected = option.id === 'danmu' ? danmuEnabled :
                              option.id === 'spectrum' ? spectrumPriority :
                              (currentPreset === option.id && isRunning);

            return (
            <button
              key={option.id}
                onClick={(e) => {
                  if (option.id === 'danmu') {
                    toggleDanmu();
                  } else if (option.id === 'spectrum') {
                    setSpectrumPriority(!spectrumPriority);
                    console.log('é¢‘è°±ä¼˜å…ˆæ¨¡å¼:', !spectrumPriority ? 'å¼€å¯' : 'å…³é—­');
                  } else {
                    handlePresetChange(option.id);
                  }
                  try { (e.currentTarget as any)?.blur?.(); } catch (_) {}
                }}
                    className={`
                      group relative block overflow-visible sm:overflow-hidden whitespace-nowrap
                      text-3xl sm:text-4xl md:text-5xl lg:text-6xl xl:text-7xl
                      text-center sm:text-left
                      font-black uppercase
                      mx-auto portrait:px-2
                  ${option.id === 'danmu'
                    ? (isSelected
                        ? 'text-white drop-shadow-[0_0_20px_rgba(255,255,255,0.8)] !blur-none !filter-none'
                        : 'text-white/40 blur-sm')
                    : (isSelected
                        ? 'text-white drop-shadow-[0_0_20px_rgba(255,255,255,0.8)] !blur-none !filter-none'
                      : 'text-white/40 blur-sm hover:text-white/60 hover:blur-none')
                  }
                      cursor-pointer
                      focus:outline-none focus:ring-0 focus:border-0
                      min-h-[44px] min-w-[44px]
                      px-4 py-2
                      transition-all duration-300 ease-in-out
                      // will-change-transform
                      // transform-gpu
                    `}
              style={{
                lineHeight: 1,
              }}
                  aria-pressed={option.id === 'danmu' ? danmuEnabled : option.id === 'spectrum' ? spectrumPriority : (currentPreset === option.id && isRunning)}
                  aria-label={option.label}
                >
              {/* ç§»åŠ¨ç«¯ï¼šæ˜¾ç¤ºä¸¤å­—æ¯ç¼©å†™ï¼ˆéšè—å¤æ‚é€å­—åŠ¨ç”»ï¼‰ */}
              <span className="sm:hidden inline-block w-full text-center" aria-hidden>
                {option.abbrMobile || option.label.slice(0, 2).toUpperCase()}
              </span>

              {/* æ¡Œé¢ç«¯ï¼šä¿ç•™åŸæœ‰é€å­—åŠ¨ç”»æ•ˆæœ */}
              {/* ä¸Šå±‚æ–‡å­— - æ‚¬åœæ—¶å‘ä¸Šç§»åŠ¨ */}
              <div className="hidden sm:flex relative">
                {graphemes.map((grapheme, i) => (
                  <span
                    key={`top-${i}`}
                    className={`inline-block transition-transform duration-300 ease-in-out ${option.id !== 'danmu' ? 'group-hover:-translate-y-[120%]' : ''} ${isSelected ? '-translate-y-[180%] opacity-0' : ''} ${option.id === 'danmu' && !isSelected ? 'blur-sm' : ''}`}
                    style={{
                      transitionDelay: `${Math.abs(i - centerIndex) * 25}ms`,
                    }}
                  >
                     {graphemes[i]}
                  </span>
                ))}
          </div>

              {/* ä¸‹å±‚æ–‡å­— - æ‚¬åœæ—¶ä»ä¸‹æ–¹æ»‘å…¥ */}
              <div className="hidden sm:flex absolute inset-0 justify-center items-center">
                {graphemes.map((grapheme, i) => (
                  <span
                    key={`bottom-${i}`}
                    className={`inline-block transition-transform duration-300 ease-in-out ${isSelected ? 'translate-y-0 opacity-100' : 'translate-y-[180%] opacity-0'} ${option.id !== 'danmu' ? 'group-hover:translate-y-0 group-hover:opacity-100' : ''}`}
                    style={{
                      transitionDelay: `${Math.abs(i - centerIndex) * 25}ms`,
                    }}
                  >
                     {graphemes[i]}
                  </span>
                ))}
              </div>

            </button>
            );
          })}
        </div>
      </div>
    </div>
  );
}
