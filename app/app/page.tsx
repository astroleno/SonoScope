'use client';

import { useState, useRef } from 'react';
import Visualizer from '../components/visualizer';
import Meyda from 'meyda';
import { useDanmuPipeline } from '../hooks/useDanmuPipeline';

export default function HomePage() {
  const [isStarted, setIsStarted] = useState(false);
  const [status, setStatus] = useState('ç­‰å¾…å¯åŠ¨');
  const [audioLevel, setAudioLevel] = useState(0);
  const [error, setError] = useState<string | null>(null);
  const [deviceInfo, setDeviceInfo] = useState<string>('');
  const [testMode, setTestMode] = useState(false);
  const [signalOn, setSignalOn] = useState(false);
  const [peak, setPeak] = useState(0);
  const [preset, setPreset] = useState<'pulse' | 'accretion' | 'spiral'>(
    'pulse'
  );
  const [accretionCtrl, setAccretionCtrl] = useState({
    sensMin: 0.92,
    sensMax: 1.18,
    gainScale: 1.15,
    flickerStrength: 0.1,
    flickerFreq: 14,
    overallBoost: 1.1,
  });
  // const [frequencyBars, setFrequencyBars] = useState<number[]>([]); // legacy, not used now
  const [features, setFeatures] = useState<{
    rms?: number;
    spectralCentroid?: number;
    zcr?: number;
    mfcc?: number[];
    spectralFlatness?: number;
    spectralFlux?: number;
  } | null>(null);
  const [sensitivity, setSensitivity] = useState<number>(1.5);
  const [rawMic, setRawMic] = useState<boolean>(false);
  const [autoCalibrate, setAutoCalibrate] = useState<boolean>(true);
  const noiseFloorRef = useRef<number>(0);

  // å¼¹å¹•ç®¡çº¿
  const danmuPipeline = useDanmuPipeline({
    enabled: true,
    autoStart: false, // æ‰‹åŠ¨å¯åŠ¨
    needComments: 4,
    locale: 'zh-CN',
    rmsThreshold: 0.05,
    maxConcurrency: 2,
  });

  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const microphoneRef = useRef<MediaStreamAudioSourceNode | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const animationFrameRef = useRef<number | null>(null);
  const isRunningRef = useRef<boolean>(false);
  const meydaAnalyzerRef = useRef<any | null>(null);

  const handleStart = async () => {
    try {
      setStatus('è¯·æ±‚éº¦å…‹é£æƒé™...');
      console.log('è¯·æ±‚éº¦å…‹é£æƒé™...');

      // å…ˆè¯·æ±‚æƒé™ï¼Œå† enumerateDevicesï¼Œä»¥é¿å… Safari/æƒé™ç­–ç•¥å¯¼è‡´çš„è®¾å¤‡åˆ—è¡¨ç©º/æ— æ ‡ç­¾
      const provisionalStream = await navigator.mediaDevices.getUserMedia({
        audio: true,
      });

      setStatus('æ£€æŸ¥éŸ³é¢‘è®¾å¤‡...');
      console.log('æ£€æŸ¥éŸ³é¢‘è®¾å¤‡...');
      const devices = await navigator.mediaDevices.enumerateDevices();
      const audioInputs = devices.filter(d => d.kind === 'audioinput');
      if (audioInputs.length === 0) {
        // æ¸…ç†ä¸´æ—¶æµ
        provisionalStream.getTracks().forEach(t => t.stop());
        throw new Error('æœªæ£€æµ‹åˆ°éŸ³é¢‘è¾“å…¥è®¾å¤‡ï¼Œè¯·è¿æ¥éº¦å…‹é£æˆ–è€³æœº');
      }

      // ä¼˜å…ˆä½¿ç”¨æœ‰æ ‡ç­¾çš„ç¬¬ä¸€ä¸ªè®¾å¤‡
      const preferred = audioInputs.find(d => !!d.label) ?? audioInputs[0];
      const deviceId = preferred.deviceId;

      // å…³é—­ä¸´æ—¶æµï¼Œä½¿ç”¨æŒ‡å®š deviceId é‡æ–°è·å–åª’ä½“æµ
      provisionalStream.getTracks().forEach(t => t.stop());

      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          deviceId: deviceId ? { exact: deviceId } : undefined,
          echoCancellation: rawMic ? false : true,
          noiseSuppression: rawMic ? false : true,
          autoGainControl: rawMic ? false : true,
          sampleRate: 44100,
        },
      });

      // æ˜¾ç¤ºè®¾å¤‡ä¿¡æ¯
      const nameList = audioInputs.map(d => d.label || 'æœªçŸ¥è®¾å¤‡').join(', ');
      setDeviceInfo(
        `æ£€æµ‹åˆ° ${audioInputs.length} ä¸ªéŸ³é¢‘è®¾å¤‡ï¼Œå½“å‰: ${preferred.label || 'æœªçŸ¥'}ï¼›å…¨éƒ¨: ${nameList}`
      );

      setStatus('åˆå§‹åŒ–éŸ³é¢‘åˆ†æ...');
      console.log('åˆå§‹åŒ–éŸ³é¢‘åˆ†æ...');

      // åˆ›å»ºéŸ³é¢‘ä¸Šä¸‹æ–‡
      const audioContext = new (window.AudioContext ||
        (window as any).webkitAudioContext)();
      const analyser = audioContext.createAnalyser();
      const microphone = audioContext.createMediaStreamSource(stream);

      // ç¡®ä¿éŸ³é¢‘ä¸Šä¸‹æ–‡è¿è¡Œ
      try {
        if (audioContext.state !== 'running') {
          await audioContext.resume();
          console.log('AudioContext å·²æ¢å¤:', audioContext.state);
        }
      } catch (resumeErr) {
        console.warn('AudioContext æ¢å¤å¤±è´¥:', resumeErr);
      }

      // å¯ç”¨éŸ³è½¨
      try {
        stream.getAudioTracks().forEach(track => {
          if (!track.enabled) track.enabled = true;
        });
      } catch (e) {
        console.warn('æ— æ³•è®¾ç½®éŸ³è½¨å¯ç”¨çŠ¶æ€:', e);
      }

      // é…ç½®åˆ†æå™¨
      analyser.fftSize = 2048;
      analyser.smoothingTimeConstant = 0.5;

      // è¿æ¥
      microphone.connect(analyser);

      // ä¿å­˜å¼•ç”¨
      audioContextRef.current = audioContext;
      analyserRef.current = analyser;
      microphoneRef.current = microphone;
      streamRef.current = stream;

      // åˆå§‹åŒ– Meyda ç‰¹å¾æå–
      try {
        if (Meyda && (Meyda as any).isBrowser) {
          meydaAnalyzerRef.current = Meyda.createMeydaAnalyzer({
            audioContext,
            source: microphone,
            bufferSize: 1024,
            featureExtractors: [
              'rms',
              'spectralCentroid',
              'zcr',
              'mfcc',
              'spectralFlatness',
              'spectralFlux',
            ],
            callback: (f: any) => {
              try {
                setFeatures({
                  rms: typeof f.rms === 'number' ? f.rms : undefined,
                  spectralCentroid:
                    typeof f.spectralCentroid === 'number'
                      ? f.spectralCentroid
                      : undefined,
                  zcr: typeof f.zcr === 'number' ? f.zcr : undefined,
                  mfcc: Array.isArray(f.mfcc) ? f.mfcc : undefined,
                  spectralFlatness:
                    typeof f.spectralFlatness === 'number'
                      ? f.spectralFlatness
                      : undefined,
                  spectralFlux:
                    typeof f.spectralFlux === 'number'
                      ? f.spectralFlux
                      : undefined,
                });
              } catch (e) {
                // ignore per-frame errors
              }
            },
          });
          meydaAnalyzerRef.current.start();
        }
      } catch (e) {
        console.warn('Meyda åˆå§‹åŒ–å¤±è´¥:', e);
      }

      setStatus('å¼€å§‹éŸ³é¢‘åˆ†æ...');
      console.log('å¼€å§‹éŸ³é¢‘åˆ†æ...');

      // å…ˆæ ‡è®°ä¸ºè¿è¡Œï¼Œå†å¯åŠ¨å¾ªç¯ï¼Œé¿å…é—­åŒ…æ•è·æ—§çŠ¶æ€
      isRunningRef.current = true;
      setIsStarted(true);
      startAudioAnalysis();

      // å¯åŠ¨å¼¹å¹•ç®¡çº¿
      if (danmuPipeline.isReady) {
        danmuPipeline.start();
      }

      setStatus('éŸ³é¢‘åˆ†æå·²å¯åŠ¨');
      setError(null);
      console.log('å¯åŠ¨æˆåŠŸ');
    } catch (err) {
      console.error('å¯åŠ¨å¤±è´¥:', err);
      setError(err instanceof Error ? err.message : 'å¯åŠ¨å¤±è´¥');
      setStatus('å¯åŠ¨å¤±è´¥');
    }
  };

  const startAudioAnalysis = () => {
    if (!analyserRef.current) return;

    const analyser = analyserRef.current;
    const bufferLength = analyser.fftSize; // ä½¿ç”¨æ—¶åŸŸæ•°æ®é•¿åº¦
    const timeDomainData = new Float32Array(bufferLength);
    // const freqBufferLen = analyser.frequencyBinCount;
    // const freqData = new Uint8Array(freqBufferLen);

    // ä»ä¿ç•™é¢‘è°±ä¸‹é‡‡æ ·å·¥å…·ï¼Œå¦‚åç»­éœ€è¦å¯ç”¨
    // const downsample = (src: Uint8Array, targetBins: number) => {
    //   const bins: number[] = new Array(targetBins).fill(0);
    //   const step = src.length / targetBins;
    //   for (let i = 0; i < targetBins; i++) {
    //     const start = Math.floor(i * step);
    //     const end = Math.floor((i + 1) * step);
    //     let sum = 0;
    //     const s = Math.max(start, 0);
    //     const e = Math.min(end, src.length);
    //     const count = Math.max(1, e - s);
    //     for (let j = s; j < e; j++) sum += src[j];
    //     bins[i] = sum / count / 255;
    //   }
    //   return bins;
    // };

    console.log('å¼€å§‹éŸ³é¢‘åˆ†æå¾ªç¯ï¼Œç¼“å†²åŒºé•¿åº¦:', bufferLength);

    const analyze = () => {
      if (!isRunningRef.current) return;

      try {
        if (testMode) {
          const testLevel = Math.sin(Date.now() * 0.01) * 0.5 + 0.5;
          setAudioLevel(testLevel);
          setPeak(testLevel);
          setSignalOn(testLevel > 0.01);
        } else {
          // ä½¿ç”¨æ—¶åŸŸæ•°æ®è®¡ç®— RMS ä¸å³°å€¼
          analyser.getFloatTimeDomainData(timeDomainData);

          let sumSquares = 0;
          let maxAbs = 0;
          let minVal = 1;
          let maxVal = -1;
          for (let i = 0; i < bufferLength; i++) {
            const sample = timeDomainData[i]; // [-1, 1]
            sumSquares += sample * sample;
            if (sample > maxVal) maxVal = sample;
            if (sample < minVal) minVal = sample;
            const abs = Math.abs(sample);
            if (abs > maxAbs) maxAbs = abs;
          }
          const rms = Math.sqrt(sumSquares / bufferLength); // [0, 1]
          let normalizedLevel = Math.min(Math.max(rms, 0), 1);
          // è‡ªé€‚åº”æ ¡å‡†ï¼šä¼°è®¡å™ªå£°åº•å¹¶æŠ¬å‡åŠ¨æ€èŒƒå›´
          if (autoCalibrate) {
            const prev = noiseFloorRef.current || 0;
            const alpha = normalizedLevel < 0.02 ? 0.01 : 0.002; // å®‰é™æ—¶æ›´å¿«è´´è¿‘åº•å™ª
            const floor = prev * (1 - alpha) + normalizedLevel * alpha;
            noiseFloorRef.current = Math.min(0.05, floor); // åº•å™ªä¸Šé™çº¦ 0.05
            const margin = 0.01; // å®‰å…¨è¾¹è·
            const adj = Math.max(
              0,
              normalizedLevel - (noiseFloorRef.current + margin)
            );
            normalizedLevel = Math.min(1, adj * 6); // æ”¾å¤§å‰©ä½™åŠ¨æ€èŒƒå›´
          }
          setAudioLevel(normalizedLevel);
          setPeak(maxAbs);
          setSignalOn(maxAbs > 0.008);

          // è‡ªåŠ¨è§¦å‘å¼¹å¹•ç®¡çº¿
          if (danmuPipeline.isActive && features) {
            danmuPipeline.handleAudioFeatures(normalizedLevel, features);
          }

          // é¢‘è°±è·å–ä¸ä¸‹é‡‡æ · (å·²ç§»é™¤spectrumé¢„è®¾)
          // if (preset === 'spectrum') {
          //   analyser.getByteFrequencyData(freqData);
          //   setFrequencyBars(downsample(freqData, 64));
          // }

          if (maxAbs < 0.01 && normalizedLevel < 0.005) {
            if (
              !(window as any).__lastQuietLog ||
              Date.now() - (window as any).__lastQuietLog > 2000
            ) {
              (window as any).__lastQuietLog = Date.now();
              console.log(
                'é™éŸ³åŒºé—´è°ƒè¯•: maxAbs=',
                maxAbs.toFixed(4),
                'RMS=',
                normalizedLevel.toFixed(4),
                'min=',
                minVal.toFixed(3),
                'max=',
                maxVal.toFixed(3)
              );
            }
          }
        }

        // ç»§ç»­åˆ†æå¾ªç¯
        animationFrameRef.current = requestAnimationFrame(analyze);
      } catch (error) {
        console.error('éŸ³é¢‘åˆ†æé”™è¯¯:', error);
        animationFrameRef.current = requestAnimationFrame(analyze);
      }
    };

    animationFrameRef.current = requestAnimationFrame(analyze);
  };

  const handleStop = () => {
    // åœæ­¢éŸ³é¢‘åˆ†æå¾ªç¯
    isRunningRef.current = false;
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }

    // åœæ­¢ Meyda
    try {
      if (meydaAnalyzerRef.current) {
        meydaAnalyzerRef.current.stop();
        meydaAnalyzerRef.current = null;
      }
    } catch (e) {
      console.warn('åœæ­¢ Meyda å¤±è´¥:', e);
    }

    // æ–­å¼€éŸ³é¢‘è¿æ¥
    if (microphoneRef.current) {
      microphoneRef.current.disconnect();
      microphoneRef.current = null;
    }

    // åœæ­¢åª’ä½“æµ
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }

    // å…³é—­éŸ³é¢‘ä¸Šä¸‹æ–‡
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }

    analyserRef.current = null;

    // åœæ­¢å¼¹å¹•ç®¡çº¿
    danmuPipeline.stop();

    setIsStarted(false);
    setStatus('ç­‰å¾…å¯åŠ¨');
    setAudioLevel(0);
    console.log('å·²åœæ­¢');
  };

  return (
    <main className="min-h-screen bg-black text-white flex flex-col items-center justify-center relative">
      {/* æ ‡é¢˜ */}
      <div className="text-center mb-8 z-10">
        <h1 className="text-4xl font-bold mb-2 bg-gradient-to-r from-blue-400 to-purple-600 bg-clip-text text-transparent">
          SonoScope
        </h1>
        <p className="text-lg text-gray-300">å®æ—¶éŸ³ä¹å¯è§†åŒ–ä¸å¼¹å¹•å¼•æ“</p>
      </div>

      {/* Accretion æ§åˆ¶é¢æ¿ */}
      {isStarted && preset === 'accretion' && (
        <div className="mt-4 z-10 w-[min(92vw,680px)] bg-white/5 border border-white/10 rounded-lg p-4 text-sm">
          <div className="mb-2 text-gray-300 font-semibold">
            Accretion æ§åˆ¶é¢æ¿
          </div>
          <div className="grid md:grid-cols-2 gap-4">
            <div>
              <label className="block text-xs text-gray-400 mb-1">
                çµæ•åº¦ä¸‹é™ sensMin ({accretionCtrl.sensMin.toFixed(2)})
              </label>
              <input
                type="range"
                min={0.85}
                max={1.1}
                step={0.01}
                value={accretionCtrl.sensMin}
                onChange={e =>
                  setAccretionCtrl(v => ({
                    ...v,
                    sensMin: Math.min(
                      parseFloat(e.target.value),
                      v.sensMax - 0.01
                    ),
                  }))
                }
                className="w-full"
              />
            </div>
            <div>
              <label className="block text-xs text-gray-400 mb-1">
                çµæ•åº¦ä¸Šé™ sensMax ({accretionCtrl.sensMax.toFixed(2)})
              </label>
              <input
                type="range"
                min={1.0}
                max={1.5}
                step={0.01}
                value={accretionCtrl.sensMax}
                onChange={e =>
                  setAccretionCtrl(v => ({
                    ...v,
                    sensMax: Math.max(
                      parseFloat(e.target.value),
                      v.sensMin + 0.01
                    ),
                  }))
                }
                className="w-full"
              />
            </div>
            <div>
              <label className="block text-xs text-gray-400 mb-1">
                å¢ç›Šæ¯”ä¾‹ gainScale ({accretionCtrl.gainScale.toFixed(2)})
              </label>
              <input
                type="range"
                min={0.6}
                max={1.8}
                step={0.02}
                value={accretionCtrl.gainScale}
                onChange={e =>
                  setAccretionCtrl(v => ({
                    ...v,
                    gainScale: parseFloat(e.target.value),
                  }))
                }
                className="w-full"
              />
            </div>
            <div>
              <label className="block text-xs text-gray-400 mb-1">
                æ€»ä½“äº®åº¦ overallBoost (
                {(accretionCtrl as any).overallBoost?.toFixed(2) ?? '1.00'})
              </label>
              <input
                type="range"
                min={0.7}
                max={1.6}
                step={0.02}
                value={(accretionCtrl as any).overallBoost ?? 1.0}
                onChange={e =>
                  setAccretionCtrl(v => ({
                    ...v,
                    overallBoost: parseFloat(e.target.value),
                  }))
                }
                className="w-full"
              />
            </div>
            <div>
              <label className="block text-xs text-gray-400 mb-1">
                é—ªçƒå¼ºåº¦ flickerStrength (
                {accretionCtrl.flickerStrength.toFixed(2)})
              </label>
              <input
                type="range"
                min={0.0}
                max={0.35}
                step={0.01}
                value={accretionCtrl.flickerStrength}
                onChange={e =>
                  setAccretionCtrl(v => ({
                    ...v,
                    flickerStrength: parseFloat(e.target.value),
                  }))
                }
                className="w-full"
              />
            </div>
            <div className="md:col-span-2">
              <label className="block text-xs text-gray-400 mb-1">
                é—ªçƒé¢‘ç‡ flickerFreq ({accretionCtrl.flickerFreq.toFixed(0)})
              </label>
              <input
                type="range"
                min={6}
                max={32}
                step={1}
                value={accretionCtrl.flickerFreq}
                onChange={e =>
                  setAccretionCtrl(v => ({
                    ...v,
                    flickerFreq: parseFloat(e.target.value),
                  }))
                }
                className="w-full"
              />
            </div>
          </div>
        </div>
      )}

      {/* é”™è¯¯æ˜¾ç¤º */}
      {error && (
        <div className="mb-4 z-10 p-4 bg-red-900/50 border border-red-500 rounded-lg">
          <p className="text-red-300 text-sm">{error}</p>
        </div>
      )}

      {/* çŠ¶æ€æ˜¾ç¤º */}
      <div className="mb-6 z-10">
        {isStarted ? (
          <div className="flex items-center space-x-2 text-green-400">
            <div className="w-3 h-3 bg-green-400 rounded-full animate-pulse"></div>
            <span>{status}</span>
          </div>
        ) : (
          <div className="flex items-center space-x-2 text-gray-400">
            <div className="w-3 h-3 bg-gray-400 rounded-full"></div>
            <span>{status}</span>
          </div>
        )}

        {/* å¼¹å¹•ç®¡çº¿çŠ¶æ€ */}
        {isStarted && (
          <div className="mt-2 text-xs text-gray-300">
            <span>å¼¹å¹•: {danmuPipeline.isActive ? 'æ´»è·ƒ' : 'åœæ­¢'}</span>
            {danmuPipeline.currentStyle && (
              <span className="ml-2">é£æ ¼: {danmuPipeline.currentStyle}</span>
            )}
            <span className="ml-2">æ•°é‡: {danmuPipeline.danmuCount}</span>
            {danmuPipeline.pendingRequests > 0 && (
              <span className="ml-2">
                ç”Ÿæˆä¸­: {danmuPipeline.pendingRequests}
              </span>
            )}
          </div>
        )}
      </div>

      {/* éº¦å…‹é£çŠ¶æ€é¢æ¿ */}
      {isStarted && (
        <div className="mb-4 z-10 px-4 py-3 bg-white/5 border border-white/10 rounded-lg text-sm text-gray-200">
          <div className="flex items-center gap-3 flex-wrap">
            <div className="flex items-center gap-2">
              <span
                className={`inline-block w-2.5 h-2.5 rounded-full ${signalOn ? 'bg-green-400' : 'bg-gray-500'}`}
              ></span>
              <span>{signalOn ? 'æœ‰ä¿¡å·' : 'æ— ä¿¡å·'}</span>
            </div>
            <div className="flex items-center gap-2">
              <span className="text-gray-400">å³°å€¼:</span>
              <span>{Math.round(peak * 100)}%</span>
            </div>
            <div className="truncate max-w-[50vw] text-gray-400">
              {deviceInfo || 'è®¾å¤‡ä¿¡æ¯è·å–ä¸­...'}
            </div>
            <div className="flex items-center gap-2 text-gray-400">
              <span>è½¨é“:</span>
              <span>
                {streamRef.current &&
                streamRef.current.getAudioTracks().length > 0
                  ? streamRef.current.getAudioTracks()[0].muted
                    ? 'å·²é™éŸ³'
                    : 'æ´»åŠ¨'
                  : 'æœªè¿æ¥'}
              </span>
            </div>
          </div>
        </div>
      )}

      {/* éŸ³é¢‘çº§åˆ«æŒ‡ç¤ºå™¨ */}
      {isStarted && (
        <div className="mb-6 z-10 w-64">
          <div className="flex items-center justify-between mb-2">
            <span className="text-sm text-gray-400">éŸ³é¢‘çº§åˆ«</span>
            <span className="text-sm text-gray-400">
              {Math.round(audioLevel * 100)}%
            </span>
          </div>
          <div className="w-full bg-gray-700 rounded-full h-2">
            <div
              className="bg-gradient-to-r from-green-500 to-red-500 h-2 rounded-full transition-all duration-100"
              style={{ width: `${audioLevel * 100}%` }}
            ></div>
          </div>
        </div>
      )}

      {/* æ§åˆ¶æŒ‰é’® */}
      <div className="flex gap-4 z-10">
        {/* é¢„è®¾é€‰æ‹© */}
        <select
          value={preset}
          onChange={e =>
            setPreset(e.target.value as 'pulse' | 'accretion' | 'spiral')
          }
          className="px-3 py-3 bg-gray-700 text-white rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500"
          aria-label="å¯è§†åŒ–é¢„è®¾"
        >
          <option value="pulse">è„‰å†²åœ†ç¯</option>
          <option value="accretion">Accretion</option>
          <option value="spiral">Spiral</option>
        </select>

        {/* ååº”å¼ºåº¦ */}
        <div className="flex items-center gap-2 text-gray-300">
          <span className="text-xs">ååº”å¼ºåº¦</span>
          <input
            type="range"
            min={0.5}
            max={3}
            step={0.1}
            value={sensitivity}
            onChange={e => setSensitivity(Number(e.target.value))}
            className="w-32"
            aria-label="ååº”å¼ºåº¦"
          />
          <span className="text-xs w-8 text-right">
            {sensitivity.toFixed(1)}x
          </span>
        </div>

        {/* åŸå§‹éº¦å…‹é£ */}
        <label className="flex items-center gap-2 text-xs text-gray-300">
          <input
            type="checkbox"
            checked={rawMic}
            onChange={e => setRawMic(e.target.checked)}
          />
          åŸå§‹éº¦å…‹é£(å…³é™å™ª/è‡ªåŠ¨å¢ç›Š)
        </label>

        {/* è‡ªé€‚åº”æ ¡å‡† */}
        <label className="flex items-center gap-2 text-xs text-gray-300">
          <input
            type="checkbox"
            checked={autoCalibrate}
            onChange={e => setAutoCalibrate(e.target.checked)}
          />
          è‡ªé€‚åº”æ ¡å‡†
        </label>
        <button
          onClick={handleStart}
          disabled={isStarted}
          className="px-8 py-4 bg-green-600 text-white rounded-lg hover:bg-green-700 focus:outline-none focus:ring-2 focus:ring-green-500 disabled:opacity-50 disabled:cursor-not-allowed transition-all"
        >
          å¼€å§‹
        </button>
        <button
          onClick={handleStop}
          disabled={!isStarted}
          className="px-8 py-4 bg-red-600 text-white rounded-lg hover:bg-red-700 focus:outline-none focus:ring-2 focus:ring-red-500 disabled:opacity-50 disabled:cursor-not-allowed transition-all"
        >
          åœæ­¢
        </button>
        <button
          onClick={() => danmuPipeline.trigger()}
          disabled={!isStarted || !danmuPipeline.isActive}
          className={`px-6 py-4 rounded-lg focus:outline-none focus:ring-2 transition-all ${
            isStarted && danmuPipeline.isActive
              ? 'bg-blue-600 text-white hover:bg-blue-700 focus:ring-blue-500'
              : 'bg-gray-600 text-white opacity-50 cursor-not-allowed'
          }`}
        >
          æ‰‹åŠ¨å¼¹å¹•
        </button>
        <button
          onClick={() => setTestMode(!testMode)}
          className={`px-6 py-4 rounded-lg focus:outline-none focus:ring-2 transition-all ${
            testMode
              ? 'bg-yellow-600 text-white hover:bg-yellow-700 focus:ring-yellow-500'
              : 'bg-gray-600 text-white hover:bg-gray-700 focus:ring-gray-500'
          }`}
        >
          {testMode ? 'é€€å‡ºæµ‹è¯•' : 'æµ‹è¯•æ¨¡å¼'}
        </button>
      </div>

      {/* è®¾å¤‡ä¿¡æ¯ */}
      {deviceInfo && (
        <div className="mt-4 max-w-lg text-center text-gray-400 z-10">
          <p className="text-xs">{deviceInfo}</p>
        </div>
      )}

      {/* ä½¿ç”¨è¯´æ˜ */}
      <div className="mt-8 max-w-lg text-center text-gray-400 z-10">
        <p className="text-sm">
          ç‚¹å‡»&ldquo;å¼€å§‹&rdquo;æŒ‰é’®æˆæƒéº¦å…‹é£è®¿é—®ï¼Œç„¶åæ’­æ”¾éŸ³ä¹æˆ–å‘å‡ºå£°éŸ³æ¥ä½“éªŒå®æ—¶å¯è§†åŒ–æ•ˆæœ
        </p>
        {!isStarted && (
          <p className="text-xs mt-2 text-yellow-400">
            ğŸ’¡ å¦‚æœæ²¡æœ‰éº¦å…‹é£ï¼Œå¯ä»¥è¿æ¥è€³æœºæˆ–ä½¿ç”¨å†…ç½®éº¦å…‹é£
          </p>
        )}
        {isStarted && (
          <div className="mt-4 text-xs text-gray-500">
            <p>ğŸ”§ è°ƒè¯•ä¿¡æ¯ï¼š</p>
            <p>â€¢ æµ‹è¯•æ¨¡å¼: {testMode ? 'å¼€å¯' : 'å…³é—­'}</p>
            <p>â€¢ éŸ³é¢‘ä¸Šä¸‹æ–‡: {audioContextRef.current ? 'å·²åˆ›å»º' : 'æœªåˆ›å»º'}</p>
            <p>â€¢ åˆ†æå™¨: {analyserRef.current ? 'å·²è¿æ¥' : 'æœªè¿æ¥'}</p>
            <p>â€¢ éº¦å…‹é£: {microphoneRef.current ? 'å·²è¿æ¥' : 'æœªè¿æ¥'}</p>
          </div>
        )}
      </div>

      {/* ç”»å¸ƒå®¹å™¨ */}
      <div
        id="visual-canvas"
        className="absolute inset-0 pointer-events-none"
      />
      <div
        id="danmu-container"
        className="absolute inset-0 pointer-events-none"
      />
      <Visualizer
        key={preset}
        audioLevel={
          testMode ? Math.sin(Date.now() * 0.01) * 0.5 + 0.5 : audioLevel
        }
        running={isStarted}
        preset={preset}
        features={features}
        sensitivity={sensitivity}
        accretionControls={accretionCtrl}
      />
    </main>
  );
}
