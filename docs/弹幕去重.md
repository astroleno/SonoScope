# SonoScope 弹幕去重与人格化执行指南

> 目标：在保持接口简单的前提下，让 `/app/api/llm-danmu/route.ts` 产出的弹幕更有个性、重复率更低、口语度更高。

---

## 1. 现状速览
- 当前 API 仅依赖 `temperature=1` 撒随机，缺少风格控制，也没有和历史弹幕比对的步骤。
- prompt 简短，未向 LLM 说明陪伴语气、人称、口语化等要求，容易生成模板化句子。
- 返回结果只做了字段类型校验，未检查长度、emoji、重复度等质量指标。

---

## 2. 改造重点（建议按顺序实施）

### 2.1 请求参数扩展
在 `route.ts` 里读取以下可选字段：
- `personaId`: 指定或自动选择微人设（默认 `auto`）。
- `existingDanmu`：最近 N 条弹幕文本，用于去重。
- `maxLength`, `enableDedup`, `enableEmojiControl` 等布尔/数字配置。

这些参数保持默认值以兼容旧调用，前端无需一次性全开。

### 2.2 Persona 与语气模版
定义一个常量数组：
```ts
const PERSONAS = [
  { id: 'quiet',  styleHint: '安静细腻，轻声细语，常用“嗯”“慢慢来”' },
  { id: 'cheer',  styleHint: '开朗热情，善用感叹号，但不过度' },
  { id: 'steady', styleHint: '稳重可靠，语句短而有力量' },
  { id: 'playful',styleHint: '活泼脑洞大，偶尔自我调侃' },
];
```
- `personaId === 'auto'` 时根据音频特征或随机挑选一位。
- 在 prompt 中追加 `styleHint`，并约束使用第一/第二人称、口语化语气词。

### 2.3 Prompt 框架
保持现有 JSON 输出约束，同时补充语气和多样性要求：
```ts
const systemPrompt = `仅输出 JSON 数组，每一项包含 text/style/color/size/speed/cooldownMs；
text 不含换行、不得超过 ${maxLength} 个汉字；style 仅限 beat|voice|complexity|random|manual。`;

const userPrompt = `角色：${personaHint}
历史弹幕：${existingDanmu.join(' / ')}
请生成 ${needDanmu} 条新弹幕${encourageHint}。
要求：
1. 使用第一人称或第二人称，让人感到被陪伴。
2. 句子 6-20 字，可含适量口语停顿词（嗯、呀、吧等），但避免过度重复。
3. 不要与“历史弹幕”出现 3-gram 以上重叠。
4. 若鼓励型，优先使用 manual 样式，并选柔和颜色。
只返回 JSON 数组。`;
```
- `existingDanmu` 为空时可写 `无`。
- 如需额外鼓励弹幕，单独在 prompt 内说明。

### 2.4 本地去重与质量校验
请求返回后按以下顺序处理：
1. **字段校验**：确保 `text`、`color` 等存在；超长时截断或剔除。
2. **N-gram 去重**：
   ```ts
   function dedupe(list: LlmDanmu[], history: string[], n = 3) {
     const seen = new Set(history.flatMap(t => extractNGram(t, n)));
     return list.filter(item => {
       const grams = extractNGram(item.text, n);
       const dup = grams.some(g => seen.has(g));
       if (!dup) grams.forEach(g => seen.add(g));
       return !dup;
     });
   }
   ```
3. **轻量正则**：限制 emoji 数量（如 >3 则剔除），确保没有全角标点堆叠。
4. 如果过滤后数量不足，允许回退到未去重版本或请求补单次。

### 2.5 输出打分与排序（可选）
- 引入简单评分：短句优先、人称符合、包含陪伴词加分。
- 依据评分排序后返回，提高整体观感。

---

## 3. 对 `route.ts` 的具体修改提示
1. **读取扩展参数**：在 `body` 解析后补充默认值，例如
   ```ts
   const personaId = body?.personaId ?? 'auto';
   const existingDanmu: string[] = Array.isArray(body?.existingDanmu) ? body.existingDanmu.slice(-20) : [];
   const maxLength = Math.min(60, Math.max(30, body?.maxLength ?? 42));
   const enableDedup = body?.enableDedup !== false;
   ```
2. **构造 persona**：根据 `personaId` 查表，或随机挑选。
3. **拼装 system/user prompt**：使用上文模板，注意 `JSON.stringify(features)` 仍可作为“线索”附在末尾。
4. **调用 LLM**：保留 `response_format` 约束；若后端支持，增加 `top_p`/`frequency_penalty` 来辅助多样化。
5. **解析结果**：
   - 拆分 `parsed` 字段后执行 `dedupe`、长度校验、颜色默认值补齐。
   - 可将 `style` 为 `manual` 的条目优先留出，避免全被去重过滤。
6. **返回结构**：继续返回 `{ success, danmuList, count }`，同时附加 `personaId` 与过滤掉的数量，便于前端调试。

---

## 4. 实施顺序 & 工时估算
| 阶段 | 任务 | 估时 |
| --- | --- | --- |
| Phase 1 | 参数扩展、prompt 升级、基础 N-gram 去重 | 4h |
| Phase 2 | persona 细节调优、emoji/长度校验、评分排序 | 4-6h |
| Phase 3 | 动态 persona/用户偏好学习、AB Test | 8-10h |

---

## 5. 验收指标
- **重复率**（3-gram 重复）：<10%。
- **人称正确率**：随机抽样 30% 弹幕，80% 以上使用第一/第二人称。
- **用户感知**：主观评测自然度 ≥4/5；多 persona 可被明确区分。
- **接口兼容性**：旧调用不带新参数时仍能正常返回。

---

通过以上改动，`/app/api/llm-danmu/route.ts` 可以在不大改架构的情况下显著提升弹幕的口语感与多样性，同时保证重复率受控。接入方只需按需传入 persona、历史弹幕等参数即可逐步启用增强能力。
