结论先说：直接面向“大模型产出弹幕”的输入，优先用文档里“建议的 Core JSON”那一组字段，再按需加少量“增强统计”。高维原始特征（如 12×Chroma、13×MFCC 等）不建议直喂。

# 一、最小可用输入（强烈建议直喂）

这些语义清晰、维度低、稳定，最适合直接驱动弹幕：

* style.label / style.confidence（风格+置信度）
* instruments.primary / secondary / probabilities / confidence（主次乐器与Top-K概率）
* tempo.bpm / beatStrength（速度与节拍力度）
* voice.probability（人声存在感）
* hpss.percussiveRatio / harmonicRatio（打击/谐波走向）
* timbre.warmth / brightness / roughness（音色三元）

另：可以把“一行英文 token 摘要”一并塞进提示，便于约束生成与打log，例如
`style=techno; instrument=drums; bpm=128; …`。

# 二、增强输入（按需少量补充，更聪明）

当你需要更具体的弹幕点（如“拍号”“稳定度”“复音度/复杂度”），再加这些聚合统计，仍保持低维：

* tempoStats.avgBpm / tempoStability / dominantTimeSignature / tempoConfidence（更稳的节奏语义）
* instrumentStats.dominantInstrument / instrumentCount / polyphony / diversity / instrumentConfidence（乐器主导与复音度）
* pitchStats.avgFundamentalFreq / dominantPitch / pitchStability / pitchConfidence（音高彩蛋、是否稳）
* enhancedHPSSStats.avgMusicalComplexity / …Stability / …Richness（整体复杂度/丰富度/稳定度）
* combinedFeatures.energy / dynamics / complexity（能量与动态范围）
* 基础聚合里的 tempo\_bpm / beat\_strength / loudness\_lkfs / dynamic\_range / voiceProb\_mean（通俗直觉的能量与节拍感）

# 三、暂不直喂（会拉低生成质量/难以约束）

以下高维、易噪或工程语义不直观的原始特征，除非你先做二次映射，否则不建议直接给大模型：

* Chroma 12维、Spectral Contrast 6维、MFCC 13维整段数组；文档也将其作为“数量汇总”而非对外接口。
* 全量 instrumentProbabilities（不截Top-K时维度大且稀疏）

# 四、输入组织小样（用于弹幕提示的建议片段）

把“最小可用输入”做成一段紧凑 JSON（即文档 Core JSON），并在提示里给出生成规范（字数、风格、多样性轮换等）。核心仍以 `style / instruments / tempo / voice / hpss / timbre` 为准。

如果需要，我可以基于你现有字段，给一版“弹幕生成 Prompt 模板 + 触发规则（比如 beatStrength 上升时输出节奏类弹幕、voiceProb 高时输出人声类弹幕、diversity 高时输出编制类弹幕）”，直接可用。&#x20;
